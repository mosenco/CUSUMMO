{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tikyn\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\aeon\\base\\__init__.py:24: FutureWarning: The aeon package will soon be releasing v1.0.0 with the removal of legacy modules and interfaces such as BaseTransformer and BaseForecaster. This will contain breaking changes. See aeon-toolkit.org for more information. Set aeon.AEON_DEPRECATION_WARNING or the AEON_DEPRECATION_WARNING environmental variable to 'False' to disable this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from claspy.segmentation import BinaryClaSPSegmentation\n",
    "\n",
    "import ruptures as rpt\n",
    "\n",
    "import stumpy\n",
    "from aeon.segmentation import find_dominant_window_sizes\n",
    "\n",
    "from aeon.segmentation import GreedyGaussianSegmenter\n",
    "\n",
    "from aeon.segmentation import InformationGainSegmenter\n",
    "\n",
    "from aeon.anomaly_detection import STRAY\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, make_scorer,mean_squared_error\n",
    "from ruptures.metrics import precision_recall\n",
    "import matplotlib.pyplot as plt\n",
    "#from aeon.visualisation import plot_series_with_change_points, plot_series_with_profiles\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()\n",
    "sns.set_color_codes()\n",
    "\n",
    "from claspy.tests.evaluation import f_measure,covering\n",
    "\n",
    "from claspy.window_size import dominant_fourier_frequency, highest_autocorrelation, suss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracted features. Use the index of this list to use with iloc[]\n",
    "<ol start=\"0\">\n",
    "  <li>Kinetic Global</li>\n",
    "  <li>Kinetic Chest</li>\n",
    "  <li>Directness Head</li>\n",
    "  <li>Density</li>\n",
    "  <li>left wrist ke</li>\n",
    "  <li>right wrist ke</li>\n",
    "  <li>left ankle ke</li>\n",
    "  <li>right ankle ke</li>\n",
    "  <li>head ke</li>\n",
    "  <li>crouch density</li>\n",
    "  <li>left leg density</li>\n",
    "  <li>right leg density</li>\n",
    "  <li>left hand density</li>\n",
    "  <li>right hand density</li>\n",
    "  <li>head density</li>\n",
    "  <li>arto inferiore</li>\n",
    "  <li>gamba</li>\n",
    "  <li>coscia</li>\n",
    "  <li>coscia dx</li>\n",
    "  <li>coscia sx</li>\n",
    "  <li>gamba sx</li>\n",
    "  <li>gamba dx</li>\n",
    "  <li>braccio sx</li>\n",
    "  <li>braccio dx</li>\n",
    "  <li>avambraccio sx</li>\n",
    "  <li>avambraccio dx</li>\n",
    "  <li>ARIEL speed magnitude</li>\n",
    "  <li>ARIEL speed X component</li>\n",
    "  <li>ARIEL speed Y component</li>\n",
    "  <li>ARIEL speed Z component</li>\n",
    "  <li>ARIEL acceleration magnitude</li>\n",
    "  <li>ARIEL acceleration X component</li>\n",
    "  <li>ARIEL acceleration Y component</li>\n",
    "  <li>ARIEL acceleration Z component</li>\n",
    "  <li>ARIEL jerk magnitude</li>\n",
    "  <li>ARIEL jerk X component</li>\n",
    "  <li>ARIEL jerk Y component</li>\n",
    "  <li>ARIEL jerk Z component</li>\n",
    "  <li>STRN speed magnitude</li>\n",
    "  <li>STRN speed X component</li>\n",
    "  <li>STRN speed Y component</li>\n",
    "  <li>STRN speed Z component</li>\n",
    "  <li>STRN acceleration magnitude</li>\n",
    "  <li>STRN acceleration X component</li>\n",
    "  <li>STRN acceleration Y component</li>\n",
    "  <li>STRN accelerationZ component</li>\n",
    "  <li>STRN jerk magnitude</li>\n",
    "  <li>STRN jerk X component</li>\n",
    "  <li>STRN jerk Y component</li>\n",
    "  <li>STRN jerk Z component</li>\n",
    "  <li>RHEL speed magnitude</li>\n",
    "  <li>RHEL speed X component</li>\n",
    "  <li>RHEL speed Y component</li>\n",
    "  <li>RHEL speed Z component</li>\n",
    "  <li>RHEL acceleration magnitude</li>\n",
    "  <li>RHEL acceleration X component</li>\n",
    "  <li>RHEL acceleration Y component</li>\n",
    "  <li>RHEL acceleration Z component</li>\n",
    "  <li>RHEL jerk magnitude</li>\n",
    "  <li>RHEL jerk X component</li>\n",
    "  <li>RHEL jerk Y component</li>\n",
    "  <li>RHEL jerk Z component</li>\n",
    "  <li>LHEL speed magnitude</li>\n",
    "  <li>LHEL speed X component</li>\n",
    "  <li>LHEL speed Y component</li>\n",
    "  <li>LHEL speed Z component</li>\n",
    "  <li>LHEL acceleration magnitude</li>\n",
    "  <li>LHEL acceleration X component</li>\n",
    "  <li>LHEL acceleration Y component</li>\n",
    "  <li>LHEL acceleration Z component</li>\n",
    "  <li>LHEL jerk magnitude</li>\n",
    "  <li>LHEL jerk X component</li>\n",
    "  <li>LHEL jerk Y component</li>\n",
    "  <li>LHEL jerk Z component</li>\n",
    "  <li>RPLM speed magnitude</li>\n",
    "  <li>RPLM speed X component</li>\n",
    "  <li>RPLM speed Y component</li>\n",
    "  <li>RPLM speed Z component</li>\n",
    "  <li>RPLM acceleration magnitude</li>\n",
    "  <li>RPLM acceleration X component</li>\n",
    "  <li>RPLM acceleration Y component</li>\n",
    "  <li>RPLM acceleration Z component</li>\n",
    "  <li>RPLM jerk magnitude</li>\n",
    "  <li>RPLM jerk X component</li>\n",
    "  <li>RPLM jerk Y component</li>\n",
    "  <li>RPLM jerk Z component</li>\n",
    "  <li>LPLM speed magnitude</li>\n",
    "  <li>LPLM speed X component</li>\n",
    "  <li>LPLM speed Y component</li>\n",
    "  <li>LPLM speed Z component</li>\n",
    "  <li>LPLM acceleration magnitude</li>\n",
    "  <li>LPLM acceleration X component</li>\n",
    "  <li>LPLM acceleration Y component</li>\n",
    "  <li>LPLM acceleration Z component</li>\n",
    "  <li>LPLM jerk magnitude</li>\n",
    "  <li>LPLM jerk X component</li>\n",
    "  <li>LPLM jerk Y component</li>\n",
    "  <li>LPLM jerk Z component</li>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of features. To access its name or its value while using iloc\n",
    "features_name=[\n",
    "    \"kinetic_global\",\n",
    "    \"kinetic_chest\",\n",
    "    \"directness_head\",\n",
    "    \"density\",\n",
    "    \"left_wrist_ke\",\n",
    "    \"right_wrist_ke\",\n",
    "    \"left_ankle_ke\",\n",
    "    \"right_ankle_ke\",\n",
    "    \"head_ke\",\n",
    "    \"crouch_density\",\n",
    "    \"left_leg_density\",\n",
    "    \"right_leg_density\",\n",
    "    \"left_hand_density\",\n",
    "    \"right_hand_density\",\n",
    "    \"head_density\",\n",
    "    \"arto_inferiore\",\n",
    "    \"gamba\",\n",
    "    \"coscia\",\n",
    "    \"coscia_dx\",\n",
    "    \"coscia_sx\",\n",
    "    \"gamba_sx\",\n",
    "    \"gamba_dx\",\n",
    "    \"braccio_sx\",\n",
    "    \"braccio_dx\",\n",
    "    \"avambraccio_sx\",\n",
    "    \"avambraccio_dx\",\n",
    "    \"ARIEL_speed_magnitude\",\n",
    "    \"ARIEL_speed_X_component\",\n",
    "    \"ARIEL_speed_Y_component\",\n",
    "    \"ARIEL_speed_Z_component\",\n",
    "    \"ARIEL_acceleration_magnitude\",\n",
    "    \"ARIEL_acceleration_X_component\",\n",
    "    \"ARIEL_acceleration_Y_component\",\n",
    "    \"ARIEL_acceleration_Z_component\",\n",
    "    \"ARIEL_jerk_magnitude\",\n",
    "    \"ARIEL_jerk_X_component\",\n",
    "    \"ARIEL_jerk_Y_component\",\n",
    "    \"ARIEL_jerk_Z_component\",\n",
    "    \"STRN_speed_magnitude\",\n",
    "    \"STRN_speed_X_component\",\n",
    "    \"STRN_speed_Y_component\",\n",
    "    \"STRN_speed_Z_component\",\n",
    "    \"STRN_acceleration_magnitude\",\n",
    "    \"STRN_acceleration_X_component\",\n",
    "    \"STRN_acceleration_Y_component\",\n",
    "    \"STRN_acceleration_Z_component\",\n",
    "    \"STRN_jerk_magnitude\",\n",
    "    \"STRN_jerk_X_component\",\n",
    "    \"STRN_jerk_Y_component\",\n",
    "    \"STRN_jerk_Z_component\",\n",
    "    \"RHEL_speed_magnitude\",\n",
    "    \"RHEL_speed_X_component\",\n",
    "    \"RHEL_speed_Y_component\",\n",
    "    \"RHEL_speed_Z_component\",\n",
    "    \"RHEL_acceleration_magnitude\",\n",
    "    \"RHEL_acceleration_X_component\",\n",
    "    \"RHEL_acceleration_Y_component\",\n",
    "    \"RHEL_acceleration_Z_component\",\n",
    "    \"RHEL_jerk_magnitude\",\n",
    "    \"RHEL_jerk_X_component\",\n",
    "    \"RHEL_jerk_Y_component\",\n",
    "    \"RHEL_jerk_Z_component\",\n",
    "    \"LHEL_speed_magnitude\",\n",
    "    \"LHEL_speed_X_component\",\n",
    "    \"LHEL_speed_Y_component\",\n",
    "    \"LHEL_speed_Z_component\",\n",
    "    \"LHEL_acceleration_magnitude\",\n",
    "    \"LHEL_acceleration_X_component\",\n",
    "    \"LHEL_acceleration_Y_component\",\n",
    "    \"LHEL_acceleration_Z_component\",\n",
    "    \"LHEL_jerk_magnitude\",\n",
    "    \"LHEL_jerk_X_component\",\n",
    "    \"LHEL_jerk_Y_component\",\n",
    "    \"LHEL_jerk_Z_component\",\n",
    "    \"RPLM_speed_magnitude\",\n",
    "    \"RPLM_speed_X_component\",\n",
    "    \"RPLM_speed_Y_component\",\n",
    "    \"RPLM_speed_Z_component\",\n",
    "    \"RPLM_acceleration_magnitude\",\n",
    "    \"RPLM_acceleration_X_component\",\n",
    "    \"RPLM_acceleration_Y_component\",\n",
    "    \"RPLM_acceleration_Z_component\",\n",
    "    \"RPLM_jerk_magnitude\",\n",
    "    \"RPLM_jerk_X_component\",\n",
    "    \"RPLM_jerk_Y_component\",\n",
    "    \"RPLM_jerk_Z_component\",\n",
    "    \"LPLM_speed_magnitude\",\n",
    "    \"LPLM_speed_X_component\",\n",
    "    \"LPLM_speed_Y_component\",\n",
    "    \"LPLM_speed_Z_component\",\n",
    "    \"LPLM_acceleration_magnitude\",\n",
    "    \"LPLM_acceleration_X_component\",\n",
    "    \"LPLM_acceleration_Y_component\",\n",
    "    \"LPLM_acceleration_Z_component\",\n",
    "    \"LPLM_jerk_magnitude\",\n",
    "    \"LPLM_jerk_X_component\",\n",
    "    \"LPLM_jerk_Y_component\",\n",
    "    \"LPLM_jerk_Z_component\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1scoremargin(ground_truth, predictions, tolerance):\n",
    "    \"\"\"\n",
    "    Calcola l'F1 score con una finestra di tolleranza sui change points.\n",
    "    \n",
    "    :param ground_truth: Lista o array di change points reali\n",
    "    :param predictions: Lista o array di change points predetti\n",
    "    :param tolerance: La tolleranza temporale (numero di unità temporali)\n",
    "    :return: precision, recall, f1-score\n",
    "    \"\"\"\n",
    "    ground_truth = np.array(ground_truth)\n",
    "    predictions = np.array(predictions)\n",
    "    \n",
    "    # Vettori per tracciare quali punti sono stati già associati\n",
    "    matched_ground_truth = np.zeros(len(ground_truth), dtype=bool)\n",
    "    matched_predictions = np.zeros(len(predictions), dtype=bool)\n",
    "\n",
    "    mgt={key: False for key in ground_truth}\n",
    "    mcp={key: False for key in predictions}\n",
    "    #print(f'gt:{len(ground_truth)} - cp:{len(predictions)}')\n",
    "    # True Positives (TP)\n",
    "    tp = 0\n",
    "    for i, gt_point in enumerate(ground_truth):\n",
    "        for j, pred_point in enumerate(predictions):\n",
    "            \n",
    "            if not matched_predictions[j] and abs(gt_point - pred_point) <= tolerance:\n",
    "                tp += 1\n",
    "                matched_ground_truth[i] = True\n",
    "                matched_predictions[j] = True\n",
    "\n",
    "                mgt[gt_point] = True\n",
    "                mcp[pred_point] = True\n",
    "                break\n",
    "            \n",
    "    \n",
    "    # False Positives (FP) - predizioni non corrispondenti a nessun ground truth entro la tolleranza\n",
    "    fp = np.sum(~matched_predictions)\n",
    "    \n",
    "    # False Negatives (FN) - punti del ground truth non corrispondenti a nessuna predizione entro la tolleranza\n",
    "    fn = np.sum(~matched_ground_truth)\n",
    "    #print(f'tp:{tp} - fp:{fp} - fn:{fn}')\n",
    "    #print(mgt)\n",
    "    #print(mcp)\n",
    "    # Calcolo di precision, recall e F1-score\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    print(f'gt:{len(ground_truth)} cp:{len(predictions)} tp:{tp} fp:{fp} fn:{fn}')\n",
    "    return precision, recall, f1, {\"tp\":tp, \"fp\":fp, \"fn\":fn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadAndPreProcess(inputDataRaw):\n",
    "    # lettura\n",
    "    df=pd.read_csv(inputDataRaw,sep=' ', header=None).interpolate()\n",
    "    \n",
    "    df=df.drop(0, axis=1)\n",
    "    df=df.drop_duplicates()\n",
    "    df = df.iloc[:, ::-1]\n",
    " \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questa funzione ritorna un dataframe del groundtruth che viene usato specificatamente per visualizzare il gt\n",
    "# è soggetto a un preprocessing dei dati siccome l'ultimo groundtruth è dove termina il ts del gt\n",
    "# di conseguenza per farlo corrispondere, bisogna stretcharlo\n",
    "# ma ricordo di aver rifatti i dati nuovi per generare un groundtruth a fine ts, da controllare cosi che non serve stretcharlo?\n",
    "def LoadingGroundTruth(df,gtraw):\n",
    "    gt=pd.read_csv(gtraw,sep=' ', header=None)\n",
    "    gt=gt.iloc[:,0].values\n",
    "    #stretching dei dati se necessario per farlo corrispondere alla ts dei dati\n",
    "    stretch_gt = np.array([])\n",
    "    for idx,i in enumerate(gt):\n",
    "        relpos = len(df)*i/gt[-1]\n",
    "        stretch_gt = np.append(stretch_gt,relpos)\n",
    "\n",
    "    # eliminiamo l'ultimo elemento che è stato annotato solo per delimitare la lunghezza della gt simile alla ts\n",
    "    \n",
    "    return stretch_gt[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetClasp2(df,gt,known,feature, **kwargs):\n",
    "    \n",
    "    result=np.array([])\n",
    "    eachresult = []\n",
    "    eachclasp=[]\n",
    "    for i in feature:\n",
    "    \n",
    "        ts=df.iloc[:,i]\n",
    "        \n",
    "        #print(ts.head())\n",
    "        if known == 1:\n",
    "            #print(\"knwon!\")\n",
    "            clasp = BinaryClaSPSegmentation(n_segments=len(gt), validation=None)\n",
    "        else:\n",
    "            #print(\"unknown!\")\n",
    "            clasp = BinaryClaSPSegmentation(**kwargs)\n",
    "            \n",
    "        found_cps = clasp.fit_predict(ts.values)    \n",
    "\n",
    "        # c'è un bug con binseg dove un cp è oltre la lunghezza del ts\n",
    "        # faccio un loop e se eccede cambio il valore con la len(tf)-1\n",
    "        # WTF IS THIS\n",
    "        \"\"\"\n",
    "        for i in range(0,len(found_cps)):\n",
    "            if found_cps[i] >= len(ts):\n",
    "                found_cps[i] = len(ts)-1\n",
    "        \"\"\"\n",
    "        # per ogni array di cp di ogni singola feature\n",
    "        # li unisco in un unico array. in pratica faccio un OR di tutti i cp\n",
    "        result = np.sort(np.append(result,found_cps).flatten())\n",
    "        #potenziale bug.\n",
    "        #se faccio unique() mi toglie il numero di cp in un punto e quando faccio majority voting mi si toglie\n",
    "        result = np.unique(result)\n",
    "        eachresult.append(found_cps)\n",
    "        eachclasp.append(clasp)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    return result, eachresult, eachclasp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilizzo CLASP \n",
    "# prende come parametro un dataframe e restituisce il clasp score\n",
    "# gt e known vengono usati per usare il numero vero di cp se uguale a 1 sennò si cerca di predirlo se il modello lo permette\n",
    "def GetClasp3(df,gt,known,feature, **kwargs):\n",
    "    \n",
    "    result=np.array([])\n",
    "    eachresult = []\n",
    "    eachclasp=[]\n",
    "    for i in [feature]:\n",
    "    \n",
    "        ts=df.iloc[:,i]\n",
    "        \n",
    "        #print(ts.head())\n",
    "        if known == 1:\n",
    "            #print(\"knwon!\")\n",
    "            clasp = BinaryClaSPSegmentation(n_segments=len(gt), validation=None)\n",
    "        else:\n",
    "            #print(\"unknown!\")\n",
    "            clasp = BinaryClaSPSegmentation(**kwargs)\n",
    "            \n",
    "        found_cps = clasp.fit_predict(ts.values)    \n",
    "\n",
    "        # c'è un bug con binseg dove un cp è oltre la lunghezza del ts\n",
    "        # faccio un loop e se eccede cambio il valore con la len(tf)-1\n",
    "        # WTF IS THIS\n",
    "        \"\"\"\n",
    "        for i in range(0,len(found_cps)):\n",
    "            if found_cps[i] >= len(ts):\n",
    "                found_cps[i] = len(ts)-1\n",
    "        \"\"\"\n",
    "\n",
    "        # per ogni array di cp di ogni singola feature\n",
    "        # li unisco in un unico array. in pratica faccio un OR di tutti i cp\n",
    "        result = np.sort(np.append(result,found_cps).flatten())\n",
    "        result = np.unique(result)\n",
    "        eachresult.append(found_cps)\n",
    "        eachclasp.append(clasp)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    return result, eachresult, eachclasp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilizzo CLASP \n",
    "# prende come parametro un dataframe e restituisce il clasp score\n",
    "# gt e known vengono usati per usare il numero vero di cp se uguale a 1 sennò si cerca di predirlo se il modello lo permette\n",
    "def GetClasp(df,gt,known, **kwargs):\n",
    "    \n",
    "    result=np.array([])\n",
    "    eachresult = []\n",
    "    eachclasp=[]\n",
    "    for i in range(0,len(features_name)):\n",
    "    \n",
    "        ts=df.iloc[:,i]\n",
    "        \n",
    "        #print(ts.head())\n",
    "        if known == 1:\n",
    "            #print(\"knwon!\")\n",
    "            clasp = BinaryClaSPSegmentation(n_segments=len(gt), validation=None)\n",
    "        else:\n",
    "            #print(\"unknown!\")\n",
    "            clasp = BinaryClaSPSegmentation(**kwargs)\n",
    "            \n",
    "        found_cps = clasp.fit_predict(ts.values)    \n",
    "\n",
    "        # c'è un bug con binseg dove un cp è oltre la lunghezza del ts\n",
    "        # faccio un loop e se eccede cambio il valore con la len(tf)-1\n",
    "        # WTF IS THIS\n",
    "        \"\"\"\n",
    "        for i in range(0,len(found_cps)):\n",
    "            if found_cps[i] >= len(ts):\n",
    "                found_cps[i] = len(ts)-1\n",
    "        \"\"\"\n",
    "        # per ogni array di cp di ogni singola feature\n",
    "        # li unisco in un unico array. in pratica faccio un OR di tutti i cp\n",
    "        result = np.sort(np.append(result,found_cps).flatten())\n",
    "        result = np.unique(result)\n",
    "        eachresult.append(found_cps)\n",
    "        eachclasp.append(clasp)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    return result, eachresult, eachclasp\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotResult(df,gt,cp, nomeFile, margin,clasplist):\n",
    "    #da testare quando ho piu valori\n",
    "    #clasp.plot(gt_cps=gt.astype(int), heading=\"Segmentation of different umpire cricket signals\", ts_name=\"ACC\", file_path=\"segmentation_example.png\")\n",
    "\n",
    "    plt.figure(figsize=(18,9))\n",
    "    plt.plot(np.arange(len(df.iloc[:,3].values)),df.iloc[:,3].values,'blue',linewidth=0.5)\n",
    "\n",
    "    for i in gt.astype(int):\n",
    "     \n",
    "        plt.axvline(x = i, color = 'green',linewidth=1) \n",
    "            \n",
    "    for j in cp.tolist():\n",
    "        plt.axvline(x = j, color = 'red',linewidth=1,linestyle=\"-.\") \n",
    "\n",
    "    for k in gt.astype(int):\n",
    "        plt.fill_betweenx(np.array([0, 1]), k-margin, k+margin, color='green', alpha=0.3)\n",
    "    plt.xlabel(f'{nomeFile} {clasplist} {f1scoremargin(gt.astype(int),cp.astype(int),margin)}')\n",
    "\n",
    "    #plt.figure(figsize=(18,9))\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plotclasp(eachclasp,gt,margin,eachcp,feature_list):\n",
    "    #print(\"idx\"+str(asd))\n",
    "    \n",
    "    for idx,clasp in enumerate(eachclasp):\n",
    "        print(features_name[feature_list[idx]])\n",
    "        clasp.plot(gt_cps=gt.astype(int), heading=f'f1margin: {f1scoremargin(gt.astype(int),eachcp[idx].astype(int),margin)}')\n",
    "        #clasp.plot(gt_cps=None, heading=f'f1margin: {f1scoremargin(gt.astype(int),eachcp[idx].astype(int),margin)}', ts_name=\"suss\")\n",
    "\n",
    "\n",
    "        plt.xlabel(features_name[feature_list[idx]])\n",
    "        for idx2,j in enumerate(gt.astype(int)):\n",
    "            plt.fill_betweenx(np.array([0, 1]), j-margin, j+margin, color='green', alpha=0.3)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcola i vari scores dati il groundtruth e il prediction\n",
    "# puo salvare il risultato su file per evitare di perderli\n",
    "# prende come parametro nome del groundtruth, groundtruth, nome della timeseries e il prediction\n",
    "def Evaluate(modelName,gtName, gt, tsName, cp, df, margin):\n",
    "    # creo dei array di lunghezza come la ts cosi possono fare il confronto\n",
    "    # sia per il gt che per il pd\n",
    "  \n",
    "    cpnump = np.array(cp)\n",
    "    gtnump = np.array(gt)\n",
    "\n",
    "    cp_long = np.zeros(len(df)+1)\n",
    "    cp_long[cpnump.astype(int)]=1\n",
    "\n",
    "    gt_long = np.zeros(len(df)+1)\n",
    "    gt_long[gtnump.astype(int)]=1\n",
    "\n",
    "    # calcolo lo score \n",
    "    print(f'f1margin: {f1scoremargin(gt.astype(int),cp.astype(int),margin)}')\n",
    "    return f1scoremargin(gt.astype(int),cp.astype(int),margin)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IgnoreZone(idx,cpraw,gt):\n",
    "    cp = cpraw.tolist()\n",
    "    if idx == 0: #cora1\n",
    "        for i in range(len(cp)-1, -1, -1):\n",
    "            #if cp[i] > 3944.7118557910376+100 and cp[i] < 5911.693516853054-100 or cp[i] > 12845.0+100:\n",
    "            if cp[i] > gt[18]+100 and cp[i] < gt[19]-100 or cp[i]> gt[-1]+100:\n",
    "                cp.pop(i)\n",
    "                \n",
    "        \n",
    "    elif idx == 1: #cora4_05\n",
    "        for i in range(len(cp)-1, -1, -1):\n",
    "            #if cp[i]< 969.6180827886711-100 and cp[i] > 13125.469063180826+100:\n",
    "            if cp[i] < gt[0]-100 or cp[i] > gt[-1]+100:\n",
    "                cp.pop(i)\n",
    "    elif idx == 2: #cora4_08\n",
    "        for i in range(len(cp)-1, -1, -1):\n",
    "            #if cp[i] > 2874.607407407407+100 and cp[i] < 4016.935849056604-100:\n",
    "            if cp[i] > gt[-2]+100 and cp[i] < gt[-1]-100:\n",
    "                cp.pop(i)\n",
    "\n",
    "    elif idx == 17: #muriel18\n",
    "        for i in range(len(cp)-1, -1, -1):\n",
    "            #if cp[i] > 180.03455207940698+100 and cp[i] < 1227.051137077522-100 or cp[i] > 5865.505591154668+100:\n",
    "            if cp[i] > gt[0]+100 and cp[i] < gt[1]-100 or cp[i] > gt[-1]+100:\n",
    "                cp.pop(i)\n",
    "\n",
    "    elif idx == 18: #muriel26\n",
    "        for i in range(len(cp)-1, -1, -1):\n",
    "            #if cp[i] > 138.33224102186853+100 and cp[i] < 3677.231833076974-100:\n",
    "            if cp[i] > gt[0]+100 and cp[i] < gt[1]-100:\n",
    "                cp.pop(i)\n",
    "\n",
    "\n",
    "    elif idx == 21: #muriel30\n",
    "        for i in range(len(cp)-1, -1, -1):\n",
    "            #if cp[i] > 8187.634803581529+100:\n",
    "            if cp[i] > gt[26]+100 and cp[i] < gt[27]-100 or cp[i] > gt[-1]+100:\n",
    "                cp.pop(i)\n",
    "\n",
    "\n",
    "    else:\n",
    "        pass\n",
    "        #print(\"error IgnoreZone()\")\n",
    "    return np.array(cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delnear(arr,range):\n",
    "    i = 0\n",
    "    while i < len(arr) - 1:\n",
    "        # Iniziamo con il primo elemento di un potenziale gruppo\n",
    "        gruppo_inizio = i\n",
    "        gruppo_fine = i\n",
    "\n",
    "        # Cerca gli elementi che fanno parte dello stesso gruppo\n",
    "        while gruppo_fine < len(arr) - 1 and arr[gruppo_fine + 1] - arr[gruppo_fine] < range:\n",
    "            gruppo_fine += 1\n",
    "\n",
    "        # Se esiste un gruppo di più elementi\n",
    "        if gruppo_fine > gruppo_inizio:\n",
    "            # Se la distanza tra l'inizio e la fine è minore di 50, elimina l'elemento maggiore (gruppo_fine)\n",
    "            if arr[gruppo_fine] - arr[gruppo_inizio] < range:\n",
    "                arr = np.delete(arr, gruppo_fine)\n",
    "            \n",
    "            # Elimina tutti gli elementi interni al gruppo\n",
    "            arr = np.concatenate((arr[:gruppo_inizio + 1], arr[gruppo_fine:]))\n",
    "\n",
    "        # Procedi con il prossimo gruppo\n",
    "        i = gruppo_inizio + 1\n",
    "\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MajorityVoteCP(arr,margin,amount):\n",
    "    \n",
    "    # se vicino continua ad aggiungere\n",
    "\n",
    "    # se lontano e bucket presente, generare medio\n",
    "\n",
    "    # se lontano e bucket vuoto aggiornare start\n",
    "    bucket=[]\n",
    "    answer=[]\n",
    "\n",
    "    for i in range(len(arr)-1,-1,-1):\n",
    "        if bucket == []:\n",
    "            bucket.append(arr[i])\n",
    "        elif abs(arr[i]-bucket[-1]) <= margin:\n",
    "            bucket.append(arr[i])\n",
    "        elif abs(arr[i]-bucket[-1]) > margin:\n",
    "            if len(bucket) < amount:\n",
    "                bucket=[arr[i]]\n",
    "            else:\n",
    "                summ=0\n",
    "                for j in bucket:\n",
    "                    summ+=j\n",
    "                answer.append(summ/len(bucket))\n",
    "                bucket=[arr[i]]\n",
    "    if len(bucket) < amount:\n",
    "        bucket=[]\n",
    "    else:\n",
    "        summ=0\n",
    "        for j in bucket:\n",
    "            summ+=j\n",
    "        answer.append(summ/len(bucket))\n",
    "        bucket=[]\n",
    "    return np.array(answer)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries=[\n",
    "    \"in\\cora1_in.txt\",\n",
    "      \"in\\cora4_05_in.txt\",\n",
    "      \"in\\cora4_08_in.txt\",\n",
    "      \"in\\cora5_in.txt\",\n",
    "      \"in\\cora14_in.txt\",\n",
    "      \"in\\marianne7_in.txt\",\n",
    "      \"in\\marianne8_in.txt\",\n",
    "      \"in\\marianne10_in.txt\",\n",
    "      \"in\\marianne18_in.txt\",\n",
    "      \"in\\marianne19_in.txt\",\n",
    "      \"in\\marianne24_in.txt\",\n",
    "      \"in\\marianne26_in.txt\",\n",
    "      \"in\\marianne41_in.txt\",\n",
    "      \"in\\marianne42_in.txt\",\n",
    "      \"in\\marianne43_in.txt\",\n",
    "      \"in\\marianne47_in.txt\",\n",
    "      \"in\\marianne48_in.txt\",\n",
    "      \"in\\muriel18_in.txt\",\n",
    "      \"in\\muriel26_in.txt\",\n",
    "      \"in\\muriel27_in.txt\",\n",
    "      \"in\\muriel30_in.txt\"\n",
    "\n",
    "      ]\n",
    "groundtruth=[\n",
    "         \"gt\\cora_gt_2019-08-08_t001_video01.txt\",\n",
    "         \"gt\\cora_gt_2019-05-22_t004_video01.txt\",\n",
    "         \"gt\\cora_gt_2019-08-08_t004_video01.txt\",\n",
    "         \"gt\\cora5_gt.txt\",\n",
    "         \"gt\\cora_gt_2019-08-08_t014_video01.txt\",\n",
    "         \"gt\\marianne_gt_2016-03-22_t007_video01.txt\",\n",
    "         \"gt\\marianne_gt_2016-03-22_t008_video01.txt\",\n",
    "         \"gt\\marianne_gt_2016-03-22_t010_video01.txt\",\n",
    "         \"gt\\marianne_gt_2016-03-22_t018_video01.txt\",\n",
    "         \"gt\\marianne_gt_2016-03-22_t019_video01.txt\",\n",
    "         \"gt\\marianne_gt_2016-03-22_t024_video01.txt\",\n",
    "         \"gt\\marianne_gt_2016-03-22_t026_video01.txt\",\n",
    "         \"gt\\marianne_gt_2016-03-22_t041_video01.txt\",\n",
    "         \"gt\\marianne_gt_2016-03-22_t042_video01.txt\",\n",
    "         \"gt\\marianne_gt_2016-03-22_t043_video01.txt\",\n",
    "         \"gt\\marianne_gt_2016-03-22_t047_video01.txt\",\n",
    "         \"gt\\marianne_gt_2016-03-22_t048_video01.txt\",\n",
    "         \"gt\\muriel_gt_2016-03-21_t018_video01.txt\",\n",
    "         \"gt\\muriel_gt_2016-03-21_t026_video01.txt\",\n",
    "         \"gt\\muriel_gt_2016-03-21_t027_video01.txt\",\n",
    "         \"gt\\muriel_gt_2016-03-23_t030_video01.txt\"\n",
    "         ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# i compute the prediction for all the features in feature_selected\n",
    "# date queste prediction in cp, genera un array answer di prediction però col majority voting\n",
    "# answer è array bidimensionale. ogni elemento di answer è una lista di prediction\n",
    "def Test_All4(df,gt,feature_selected,nameFeature,i):\n",
    "   \n",
    "    cp,eachcp,clasp=GetClasp2(df,gt,0,feature_selected, window_size=\"suss\",distance=\"euclidean_distance\",excl_radius=4,n_jobs=8)\n",
    "   # PlotResult(df,gt,cp,timeseries[i],100,str(nameFeature)+\" raw\")\n",
    "    answer=[]\n",
    "    for j in range(1,len(feature_selected)+1):\n",
    "        answer.append(MajorityVoteCP(cp,100,j))\n",
    "        #PlotResult(df,gt,test,timeseries[i],100,\"test:\"+str(j))\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calcola prediction per solo il magnitude e solo per i 3 components xyz\n",
    "# dalle 3 component genera single_component che è prediction filtrato con majority voting\n",
    "# combina il risultato del single_component con il magnitude\n",
    "def Test_3_to_1(df,gt,feature_magnitude,feature_selected,nameFeature,i):\n",
    "\n",
    "\n",
    "    cp_magnitude,eachcp,clasp=GetClasp2(df,gt,0,feature_magnitude, window_size=\"suss\",distance=\"euclidean_distance\",excl_radius=4,n_jobs=8)\n",
    "    cp_selected,eachcp,clasp=GetClasp2(df,gt,0,feature_selected, window_size=\"suss\",distance=\"euclidean_distance\",excl_radius=4,n_jobs=8)\n",
    "    cp_sel_1 = MajorityVoteCP(cp_selected,100,1)\n",
    "    cp_sel_2 = MajorityVoteCP(cp_selected,100,2)\n",
    "    cp_sel_3 = MajorityVoteCP(cp_selected,100,3)\n",
    "   # PlotResult(df,gt,cp_sel_1,timeseries[i],100,\"cp_sel_1\")\n",
    "    #PlotResult(df,gt,cp_sel_2,timeseries[i],100,\"cp_sel_2\")\n",
    "    #PlotResult(df,gt,cp_sel_3,timeseries[i],100,\"cp_sel_3\")\n",
    "    answer_before=[]\n",
    "    answer_combined=[]\n",
    "    for j in range(1,len(feature_selected)+1):\n",
    "        single_component=MajorityVoteCP(cp_selected,100,j)\n",
    "        answer_before.append(single_component)\n",
    "\n",
    "        result=np.array([])\n",
    "        result = np.sort(np.append(cp_magnitude,single_component).flatten())\n",
    "        result_1 = MajorityVoteCP(result,100,1)\n",
    "        result_2 = MajorityVoteCP(result,100,2)\n",
    "        answer_combined.append([result_1,result_2])\n",
    "        #PlotResult(df,gt,result_1,timeseries[i],100,str(nameFeature)+\":result1\")\n",
    "        #PlotResult(df,gt,result_2,timeseries[i],100,str(nameFeature)+\":result2\")\n",
    "\n",
    "    return [answer_before,answer_combined]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tikyn\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\stats\\_stats_py.py:9205: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  z = (s - expected) / np.sqrt(n1*n2*(n1+n2+1)/12.0)\n"
     ]
    }
   ],
   "source": [
    "# compute all cp for all timeseries, so later we can use it freely\n",
    "for i in range(3,4):#len(timeseries)):\n",
    "    df=ReadAndPreProcess(timeseries[i])\n",
    "    gt=LoadingGroundTruth(df,groundtruth[i])\n",
    "    cp_all,cps,clasp=GetClasp2(df,gt,0,list(range(len(features_name))), window_size=\"suss\",distance=\"euclidean_distance\",excl_radius=4,n_jobs=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AndSal(margin,majvote,*args):\n",
    "    result=np.array([])\n",
    " \n",
    "    for cp in args:\n",
    "        result = np.append(result,cp).flatten()\n",
    "    result = np.sort(result)\n",
    "    result = MajorityVoteCP(result,margin,majvote)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.56, 0.8235294117647058, 0.6666666666666666, {'tp': 14, 'fp': 11, 'fn': 3})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a4_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt:17 cp:28 tp:13 fp:15 fn:4\n",
      "gt:17 cp:22 tp:11 fp:11 fn:6\n",
      "gt:17 cp:16 tp:9 fp:7 fn:8\n",
      "gt:17 cp:25 tp:14 fp:11 fn:3\n",
      "(0.56, 0.8235294117647058, 0.6666666666666666, {'tp': 14, 'fp': 11, 'fn': 3})\n",
      "gt:17 cp:23 tp:12 fp:11 fn:5\n",
      "(0.5217391304347826, 0.7058823529411765, 0.6, {'tp': 12, 'fp': 11, 'fn': 5})\n",
      "gt:17 cp:20 tp:11 fp:9 fn:6\n",
      "(0.55, 0.6470588235294118, 0.5945945945945946, {'tp': 11, 'fp': 9, 'fn': 6})\n",
      "(0.4642857142857143, 0.7647058823529411, 0.5777777777777777, {'tp': 13, 'fp': 15, 'fn': 4})\n",
      "(0.5, 0.6470588235294118, 0.5641025641025642, {'tp': 11, 'fp': 11, 'fn': 6})\n",
      "(0.5625, 0.5294117647058824, 0.5454545454545455, {'tp': 9, 'fp': 7, 'fn': 8})\n"
     ]
    }
   ],
   "source": [
    "a4_1=AndSal(100,1,cps[74],cps[75],cps[76],cps[77])\n",
    "a4_2=AndSal(100,1,cps[78],cps[79],cps[80],cps[81])\n",
    "a4_3=AndSal(100,1,cps[82],cps[83],cps[84],cps[85])\n",
    "\n",
    "sum_1=f1scoremargin(gt,AndSal(100,1,a4_1,a4_2,a4_3),100)\n",
    "sum_2=f1scoremargin(gt,AndSal(100,2,a4_1,a4_2,a4_3),100)\n",
    "sum_3=f1scoremargin(gt,AndSal(100,3,a4_1,a4_2,a4_3),100)\n",
    "\n",
    "print(f1scoremargin(gt,a4_1,100))\n",
    "print(f1scoremargin(gt,a4_2,100))\n",
    "print(f1scoremargin(gt,a4_3,100))\n",
    "\n",
    "print(sum_1)\n",
    "print(sum_2)\n",
    "print(sum_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def ComputeTable(vel,acc,jerk):\n",
    "    for i in range(3,4):#len(timeseries)):\n",
    "        df=ReadAndPreProcess(timeseries[i])\n",
    "        gt=LoadingGroundTruth(df,groundtruth[i])\n",
    "        \n",
    "\n",
    "        vel_4=Test_All4(df,gt,vel,\"braccio_dx\",i)\n",
    "        vel_3to1=Test_3_to_1(df,gt,[vel[0]],vel[1:],\"braccio_dx\",i)\n",
    "\n",
    "        acc_4=Test_All4(df,gt,acc,\"braccio_dx\",i)\n",
    "        acc_3to1=Test_3_to_1(df,gt,[acc[0]],acc[1:],\"braccio_dx\",i)\n",
    "\n",
    "        jerk_4=Test_All4(df,gt,jerk,\"braccio_dx\",i)\n",
    "        jerk_3to1=Test_3_to_1(df,gt,[jerk[0]],jerk[1:],\"braccio_dx\",i)\n",
    "\n",
    "        vel_score=[]\n",
    "        acc_score=[]\n",
    "        jerk_score=[]\n",
    "        vaj_score=[]\n",
    "        vel3_score=[]\n",
    "        acc3_score=[]\n",
    "        jerk3_score=[]\n",
    "        vel3_1_score=[]\n",
    "        vel3_2_score=[]\n",
    "        acc3_1_score=[]\n",
    "        acc3_2_score=[]\n",
    "        jerk3_1_score=[]\n",
    "        jerk3_2_score=[]\n",
    "        vaj_only3=[]\n",
    "        vaj_final_1=[]\n",
    "        vaj_final_2=[]\n",
    "        # calcola score di vel,acc,jerk in base al majority\n",
    "        for j in range(0,4):\n",
    "            p,r,f,d=f1scoremargin(gt,vel_4[j],100)\n",
    "            vel_score.append([f,d[\"fp\"]])\n",
    "\n",
    "            p,r,f,d=f1scoremargin(gt,acc_4[j],100)\n",
    "            acc_score.append([f,d[\"fp\"]])\n",
    "\n",
    "            p,r,f,d=f1scoremargin(gt,jerk_4[j],100)\n",
    "            jerk_score.append([f,d[\"fp\"]])\n",
    "\n",
    "        # prende i prediction di vel,acc,jerk in base al majority e calcola la somma col majority\n",
    "        for j in range(1,5):\n",
    "            vaj_4_raw = np.array([])\n",
    "            vaj_4_raw = np.sort(np.append(vaj_4_raw,vel_4[j-1]).flatten())\n",
    "            vaj_4_raw = np.sort(np.append(vaj_4_raw,acc_4[j-1]).flatten())\n",
    "            vaj_4_raw = np.sort(np.append(vaj_4_raw,jerk_4[j-1]).flatten())\n",
    "            vaj_score.append([])\n",
    "            for k in range(1,4):\n",
    "                vaj_4 = MajorityVoteCP(vaj_4_raw,100,k)\n",
    "                p,r,f,d=f1scoremargin(gt,vaj_4,100)\n",
    "                vaj_score[j-1].append([f,d[\"fp\"]])\n",
    "                #PlotResult(df,gt,vaj_4,timeseries[i],100,\"vaj_4 riga:\"+str(j)+\"maj:\"+str(k))\n",
    "        # prendo i singoli prediction solo con components senza magnitude e calcolo f1score\n",
    "        for j in range(0,3):\n",
    "            p,r,f,d=f1scoremargin(gt,vel_3to1[0][j],100)\n",
    "            vel3_score.append([f,d[\"fp\"]])\n",
    "\n",
    "            p,r,f,d=f1scoremargin(gt,acc_3to1[0][j],100)\n",
    "            acc3_score.append([f,d[\"fp\"]])\n",
    "\n",
    "            p,r,f,d=f1scoremargin(gt,jerk_3to1[0][j],100)\n",
    "            jerk3_score.append([f,d[\"fp\"]])\n",
    "\n",
    "        #3+1\n",
    "        for j in range(0,3):\n",
    "            p,r,f,d=f1scoremargin(gt,vel_3to1[1][j][0],100)\n",
    "            vel3_1_score.append([f,d[\"fp\"]])\n",
    "            p,r,f,d=f1scoremargin(gt,vel_3to1[1][j][1],100)\n",
    "            vel3_2_score.append([f,d[\"fp\"]])\n",
    "\n",
    "            p,r,f,d=f1scoremargin(gt,acc_3to1[1][j][0],100)\n",
    "            acc3_1_score.append([f,d[\"fp\"]])\n",
    "            p,r,f,d=f1scoremargin(gt,acc_3to1[1][j][1],100)\n",
    "            acc3_2_score.append([f,d[\"fp\"]])\n",
    "\n",
    "            p,r,f,d=f1scoremargin(gt,jerk_3to1[1][j][0],100)\n",
    "            jerk3_1_score.append([f,d[\"fp\"]])\n",
    "            p,r,f,d=f1scoremargin(gt,jerk_3to1[1][j][1],100)\n",
    "            jerk3_2_score.append([f,d[\"fp\"]])\n",
    "\n",
    "\n",
    "\n",
    "        for j in range(1,4):\n",
    "            vaj_3to1_raw = np.array([])\n",
    "            vaj_3to1_raw = np.sort(np.append(vaj_3to1_raw,vel_3to1[0][j-1]).flatten())\n",
    "            vaj_3to1_raw = np.sort(np.append(vaj_3to1_raw,acc_3to1[0][j-1]).flatten())\n",
    "            vaj_3to1_raw = np.sort(np.append(vaj_3to1_raw,jerk_3to1[0][j-1]).flatten())\n",
    "            vaj_only3.append([])\n",
    "            for k in range(1,4):\n",
    "                vaj_3to1 = MajorityVoteCP(vaj_3to1_raw,100,k)\n",
    "                p,r,f,d=f1scoremargin(gt,vaj_3to1,100)\n",
    "                vaj_only3[j-1].append([f,d[\"fp\"]])\n",
    "                #PlotResult(df,gt,vaj_3to1,timeseries[i],100,\"vaj_3to1_raw riga:\"+str(j)+\"maj:\"+str(k))\n",
    "\n",
    "        for j in range(1,4):\n",
    "            vaj_3to1_raw = np.array([])\n",
    "            vaj_3to1_raw = np.sort(np.append(vaj_3to1_raw,vel_3to1[1][j-1][0]).flatten())\n",
    "            vaj_3to1_raw = np.sort(np.append(vaj_3to1_raw,acc_3to1[1][j-1][0]).flatten())\n",
    "            vaj_3to1_raw = np.sort(np.append(vaj_3to1_raw,jerk_3to1[1][j-1][0]).flatten())\n",
    "            vaj_final_1.append([])\n",
    "            for k in range(1,4):\n",
    "                vaj_3to1 = MajorityVoteCP(vaj_3to1_raw,100,k)\n",
    "                p,r,f,d=f1scoremargin(gt,vaj_3to1,100)\n",
    "                vaj_final_1[j-1].append([f,d[\"fp\"]])\n",
    "                #PlotResult(df,gt,vaj_3to1,timeseries[i],100,\"vaj_3to1_1 riga:\"+str(j)+\"maj:\"+str(k))\n",
    "\n",
    "        for j in range(1,4):\n",
    "            vaj_3to1_raw = np.array([])\n",
    "            vaj_3to1_raw = np.sort(np.append(vaj_3to1_raw,vel_3to1[1][j-1][1]).flatten())\n",
    "            vaj_3to1_raw = np.sort(np.append(vaj_3to1_raw,acc_3to1[1][j-1][1]).flatten())\n",
    "            vaj_3to1_raw = np.sort(np.append(vaj_3to1_raw,jerk_3to1[1][j-1][1]).flatten())\n",
    "            vaj_final_2.append([])\n",
    "            for k in range(1,4):\n",
    "                vaj_3to1 = MajorityVoteCP(vaj_3to1_raw,100,k)\n",
    "                p,r,f,d=f1scoremargin(gt,vaj_3to1,100)\n",
    "                vaj_final_2[j-1].append([f,d[\"fp\"]])\n",
    "                #PlotResult(df,gt,vaj_3to1,timeseries[i],100,\"vaj_3to1_2 riga:\"+str(j)+\"maj:\"+str(k))\n",
    "\n",
    " \n",
    "    return [vel_score,acc_score,jerk_score,vaj_score,vel3_score,acc3_score,jerk3_score,vaj_only3,vel3_1_score,vel3_2_score,acc3_1_score,acc3_2_score,jerk3_1_score,jerk3_2_score,vaj_final_1,vaj_final_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ariel_v,ariel_a,ariel_j,ariel_vaj,ariel_v3,ariel_a3,ariel_j3,ariel_only,ariel_v3_1,ariel_v3_2,ariel_a3_1,ariel_a3_2,ariel_j3_1,ariel_j3_2,ariel_1,ariel_2=ComputeTable([26,27,28,29],[30,31,32,33],[34,35,36,37])\n",
    "strn_v,strn_a,strn_j,strn_vaj,strn_v3,strn_a3,strn_j3,strn_only,strn_v3_1,strn_v3_2,strn_a3_1,strn_a3_2,strn_j3_1,strn_j3_2,strn_1,strn_2=ComputeTable([38,39,40,41],[42,43,44,45],[46,47,48,49])\n",
    "rhel_v,rhel_a,rhel_j,rhel_vaj,rhel_v3,rhel_a3,rhel_j3,rhel_only,rhel_v3_1,rhel_v3_2,rhel_a3_1,rhel_a3_2,rhel_j3_1,rhel_j3_2,rhel_1,rhel_2=ComputeTable([50,51,52,53],[54,55,56,57],[58,59,60,61])\n",
    "lhel_v,lhel_a,lhel_j,lhel_vaj,lhel_v3,lhel_a3,lhel_j3,lhel_only,lhel_v3_1,lhel_v3_2,lhel_a3_1,lhel_a3_2,lhel_j3_1,lhel_j3_2,lhel_1,lhel_2=ComputeTable([62,63,64,65],[66,67,68,69],[70,71,72,73])\n",
    "rplm_v,rplm_a,rplm_j,rplm_vaj,rplm_v3,rplm_a3,rplm_j3,rplm_only,rplm_v3_1,rplm_v3_2,rplm_a3_1,rplm_a3_2,rplm_j3_1,rplm_j3_2,rplm_1,rplm_2=ComputeTable([74,75,76,77],[78,79,80,81],[82,83,84,85])\n",
    "lplm_v,lplm_a,lplm_j,lplm_vaj,lplm_v3,lplm_a3,lplm_j3,lplm_only,lplm_v3_1,lplm_v3_2,lplm_a3_1,lplm_a3_2,lplm_j3_1,lplm_j3_2,lplm_1,lplm_2=ComputeTable([86,87,88,89],[90,91,92,93],[94,95,96,97])\n",
    "\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"ariel_v\"]=ariel_v\n",
    "outdf[\"ariel_a\"]=ariel_a\n",
    "outdf[\"ariel_j\"]=ariel_j\n",
    "outdf.to_excel(\"outputFile/ariel1.xlsx\")\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"ariel_vaj\"]=ariel_vaj\n",
    "outdf.to_excel(\"outputFile/ariel2.xlsx\")\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"ariel_v3\"]=ariel_v3\n",
    "outdf[\"ariel_a3\"]=ariel_a3\n",
    "outdf[\"ariel_j3\"]=ariel_j3\n",
    "outdf.to_excel(\"outputFile/ariel3.xlsx\")\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"ariel_only\"]=ariel_only\n",
    "outdf.to_excel(\"outputFile/ariel4.xlsx\")\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"ariel_1\"]=ariel_1\n",
    "outdf[\"ariel_2\"]=ariel_2\n",
    "outdf.to_excel(\"outputFile/ariel5.xlsx\")\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"ariel_v3_1\"]=ariel_v3_1\n",
    "outdf[\"ariel_v3_2\"]=ariel_v3_2\n",
    "outdf[\"ariel_a3_1\"]=ariel_a3_1\n",
    "outdf[\"ariel_a3_2\"]=ariel_a3_2\n",
    "outdf[\"ariel_j3_1\"]=ariel_j3_1\n",
    "outdf[\"ariel_j3_2\"]=ariel_j3_2\n",
    "outdf.to_excel(\"outputFile/ariel6.xlsx\")\n",
    "\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"strn_v\"]=strn_v\n",
    "outdf[\"strn_a\"]=strn_a\n",
    "outdf[\"strn_j\"]=strn_j\n",
    "outdf.to_excel(\"outputFile/strn1.xlsx\")\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"strn_vaj\"]=strn_vaj\n",
    "outdf.to_excel(\"outputFile/strn2.xlsx\")\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"strn_v3\"]=strn_v3\n",
    "outdf[\"strn_a3\"]=strn_a3\n",
    "outdf[\"strn_j3\"]=strn_j3\n",
    "outdf.to_excel(\"outputFile/strn3.xlsx\")\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"strn_only\"]=strn_only\n",
    "outdf.to_excel(\"outputFile/strn4.xlsx\")\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"strn_1\"]=strn_1\n",
    "outdf[\"strn_2\"]=strn_2\n",
    "outdf.to_excel(\"outputFile/strn5.xlsx\")\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"strn_v3_1\"]=strn_v3_1\n",
    "outdf[\"strn_v3_2\"]=strn_v3_2\n",
    "outdf[\"strn_a3_1\"]=strn_a3_1\n",
    "outdf[\"strn_a3_2\"]=strn_a3_2\n",
    "outdf[\"strn_j3_1\"]=strn_j3_1\n",
    "outdf[\"strn_j3_2\"]=strn_j3_2\n",
    "outdf.to_excel(\"outputFile/strn6.xlsx\")\n",
    "\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"rhel_v\"]=rhel_v\n",
    "outdf[\"rhel_a\"]=rhel_a\n",
    "outdf[\"rhel_j\"]=rhel_j\n",
    "outdf.to_excel(\"outputFile/rhel1.xlsx\")\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"rhel_vaj\"]=rhel_vaj\n",
    "outdf.to_excel(\"outputFile/rhel2.xlsx\")\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"rhel_v3\"]=rhel_v3\n",
    "outdf[\"rhel_a3\"]=rhel_a3\n",
    "outdf[\"rhel_j3\"]=rhel_j3\n",
    "outdf.to_excel(\"outputFile/rhel3.xlsx\")\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"rhel_only\"]=rhel_only\n",
    "outdf.to_excel(\"outputFile/rhel4.xlsx\")\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"rhel_1\"]=rhel_1\n",
    "outdf[\"rhel_2\"]=rhel_2\n",
    "outdf.to_excel(\"outputFile/rhel5.xlsx\")\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"rhel_v3_1\"]=rhel_v3_1\n",
    "outdf[\"rhel_v3_2\"]=rhel_v3_2\n",
    "outdf[\"rhel_a3_1\"]=rhel_a3_1\n",
    "outdf[\"rhel_a3_2\"]=rhel_a3_2\n",
    "outdf[\"rhel_j3_1\"]=rhel_j3_1\n",
    "outdf[\"rhel_j3_2\"]=rhel_j3_2\n",
    "outdf.to_excel(\"outputFile/rhel6.xlsx\")\n",
    "\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"lhel_v\"]=lhel_v\n",
    "outdf[\"lhel_a\"]=lhel_a\n",
    "outdf[\"lhel_j\"]=lhel_j\n",
    "outdf.to_excel(\"outputFile/lhel1.xlsx\")\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"lhel_vaj\"]=lhel_vaj\n",
    "outdf.to_excel(\"outputFile/lhel2.xlsx\")\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"lhel_v3\"]=lhel_v3\n",
    "outdf[\"lhel_a3\"]=lhel_a3\n",
    "outdf[\"lhel_j3\"]=lhel_j3\n",
    "outdf.to_excel(\"outputFile/lhel3.xlsx\")\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"lhel_only\"]=lhel_only\n",
    "outdf.to_excel(\"outputFile/lhel4.xlsx\")\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"lhel_1\"]=lhel_1\n",
    "outdf[\"lhel_2\"]=lhel_2\n",
    "outdf.to_excel(\"outputFile/lhel5.xlsx\")\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"lhel_v3_1\"]=lhel_v3_1\n",
    "outdf[\"lhel_v3_2\"]=lhel_v3_2\n",
    "outdf[\"lhel_a3_1\"]=lhel_a3_1\n",
    "outdf[\"lhel_a3_2\"]=lhel_a3_2\n",
    "outdf[\"lhel_j3_1\"]=lhel_j3_1\n",
    "outdf[\"lhel_j3_2\"]=lhel_j3_2\n",
    "outdf.to_excel(\"outputFile/lhel6.xlsx\")\n",
    "\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"rplm_v\"]=rplm_v\n",
    "outdf[\"rplm_a\"]=rplm_a\n",
    "outdf[\"rplm_j\"]=rplm_j\n",
    "outdf.to_excel(\"outputFile/rplm1.xlsx\")\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"rplm_vaj\"]=rplm_vaj\n",
    "outdf.to_excel(\"outputFile/rplm2.xlsx\")\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"rplm_v3\"]=rplm_v3\n",
    "outdf[\"rplm_a3\"]=rplm_a3\n",
    "outdf[\"rplm_j3\"]=rplm_j3\n",
    "outdf.to_excel(\"outputFile/rplm3.xlsx\")\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"rplm_only\"]=rplm_only\n",
    "outdf.to_excel(\"outputFile/rplm4.xlsx\")\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"rplm_1\"]=rplm_1\n",
    "outdf[\"rplm_2\"]=rplm_2\n",
    "outdf.to_excel(\"outputFile/rplm5.xlsx\")\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"rplm_v3_1\"]=rplm_v3_1\n",
    "outdf[\"rplm_v3_2\"]=rplm_v3_2\n",
    "outdf[\"rplm_a3_1\"]=rplm_a3_1\n",
    "outdf[\"rplm_a3_2\"]=rplm_a3_2\n",
    "outdf[\"rplm_j3_1\"]=rplm_j3_1\n",
    "outdf[\"rplm_j3_2\"]=rplm_j3_2\n",
    "outdf.to_excel(\"outputFile/rplm6.xlsx\")\n",
    "\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"lplm_v\"]=lplm_v\n",
    "outdf[\"lplm_a\"]=lplm_a\n",
    "outdf[\"lplm_j\"]=lplm_j\n",
    "outdf.to_excel(\"outputFile/lplm1.xlsx\")\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"lplm_vaj\"]=lplm_vaj\n",
    "outdf.to_excel(\"outputFile/lplm2.xlsx\")\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"lplm_v3\"]=lplm_v3\n",
    "outdf[\"lplm_a3\"]=lplm_a3\n",
    "outdf[\"lplm_j3\"]=lplm_j3\n",
    "outdf.to_excel(\"outputFile/lplm3.xlsx\")\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"lplm_only\"]=lplm_only\n",
    "outdf.to_excel(\"outputFile/lplm4.xlsx\")\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"lplm_1\"]=lplm_1\n",
    "outdf[\"lplm_2\"]=lplm_2\n",
    "outdf.to_excel(\"outputFile/lplm5.xlsx\")\n",
    "outdf=pd.DataFrame()\n",
    "outdf[\"lplm_v3_1\"]=lplm_v3_1\n",
    "outdf[\"lplm_v3_2\"]=lplm_v3_2\n",
    "outdf[\"lplm_a3_1\"]=lplm_a3_1\n",
    "outdf[\"lplm_a3_2\"]=lplm_a3_2\n",
    "outdf[\"lplm_j3_1\"]=lplm_j3_1\n",
    "outdf[\"lplm_j3_2\"]=lplm_j3_2\n",
    "outdf.to_excel(\"outputFile/lplm6.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cleaned_array = [s[3:-7] for s in timeseries]\n",
    "outdf = pd.DataFrame({\"test_set\":[0,2,4,6,8,9]})\n",
    "\n",
    "for i in range(3,4):#len(timeseries)):\n",
    "    df=ReadAndPreProcess(timeseries[i])\n",
    "    gt=LoadingGroundTruth(df,groundtruth[i])\n",
    "    test_set=[0,2,4,6,8,9]\n",
    "    outeval=[]\n",
    "    \n",
    "    \n",
    "\n",
    "    #test1\n",
    "    #braccio dx\n",
    "    # velocity components\n",
    "    feature_selected=[74,75,76,77]\n",
    "    cp,eachcp,clasp=GetClasp2(df,gt,0,feature_selected, window_size=\"suss\",distance=\"euclidean_distance\",excl_radius=4,n_jobs=8)\n",
    "    test1_1=MajorityVoteCP(cp,100,1)\n",
    "    test1_2=MajorityVoteCP(cp,100,2)\n",
    "    test1_3=MajorityVoteCP(cp,100,3)\n",
    "    test1_4=MajorityVoteCP(cp,100,4)\n",
    "    PlotResult(df,gt,cp,timeseries[i],100,\"test1 raw\")\n",
    "    PlotResult(df,gt,test1_1,timeseries[i],100,\"test1_1\")\n",
    "    PlotResult(df,gt,test1_2,timeseries[i],100,\"test1_2\")\n",
    "    PlotResult(df,gt,test1_3,timeseries[i],100,\"test1_3\")\n",
    "    PlotResult(df,gt,test1_4,timeseries[i],100,\"test1_4\")\n",
    "\n",
    "    #test2\n",
    "    feature_selected=[75,76,77]\n",
    "    cp,eachcp,clasp=GetClasp2(df,gt,0,feature_selected, window_size=\"suss\",distance=\"euclidean_distance\",excl_radius=4,n_jobs=8)\n",
    "    test2_1=MajorityVoteCP(cp,100,1)\n",
    "    test2_2=MajorityVoteCP(cp,100,2)\n",
    "    test2_3=MajorityVoteCP(cp,100,3)\n",
    "\n",
    "    feature_selected=[74]\n",
    "    cp,eachcp,clasp=GetClasp2(df,gt,0,feature_selected, window_size=\"suss\",distance=\"euclidean_distance\",excl_radius=4,n_jobs=8)\n",
    "    test2_4=np.array([])\n",
    "    test2_4 = np.sort(np.append(cp,test2_1).flatten())\n",
    "    test2_4_1 = MajorityVoteCP(test2_4,100,1)\n",
    "    test2_4_2 = MajorityVoteCP(test2_4,100,2)\n",
    "\n",
    "    test2_5=np.array([])\n",
    "    test2_5 = np.sort(np.append(cp,test2_2).flatten())\n",
    "    test2_5_1 = MajorityVoteCP(test2_5,100,1)\n",
    "    test2_5_2 = MajorityVoteCP(test2_5,100,2)\n",
    "\n",
    "    test2_6=np.array([])\n",
    "    test2_6 = np.sort(np.append(cp,test2_3).flatten())\n",
    "    test2_6_1 = MajorityVoteCP(test2_6,100,1)\n",
    "    test2_6_2 = MajorityVoteCP(test2_6,100,2)\n",
    "\n",
    "    PlotResult(df,gt,test2_1,timeseries[i],100,\"test_2_1\")\n",
    "    PlotResult(df,gt,test2_2,timeseries[i],100,\"test2_2\")\n",
    "    PlotResult(df,gt,test2_3,timeseries[i],100,\"test2_3\")\n",
    "\n",
    "    PlotResult(df,gt,cp,timeseries[i],100,\"cp\")\n",
    "    PlotResult(df,gt,test2_1,timeseries[i],100,\"test_2_1\")\n",
    "    PlotResult(df,gt,test2_4_1,timeseries[i],100,\"test2_4_1\")\n",
    "    PlotResult(df,gt,test2_4_2,timeseries[i],100,\"test2_4_2\")\n",
    "\n",
    "    PlotResult(df,gt,cp,timeseries[i],100,\"cp\")\n",
    "    PlotResult(df,gt,test2_2,timeseries[i],100,\"test2_2\")\n",
    "    PlotResult(df,gt,test2_5_1,timeseries[i],100,\"test2_5_1\")\n",
    "    PlotResult(df,gt,test2_5_2,timeseries[i],100,\"test2_5_2\")\n",
    "\n",
    "    PlotResult(df,gt,cp,timeseries[i],100,\"cp\")\n",
    "    PlotResult(df,gt,test2_3,timeseries[i],100,\"test2_3\")\n",
    "    PlotResult(df,gt,test2_6_1,timeseries[i],100,\"test2_6_1\")\n",
    "    PlotResult(df,gt,test2_6_2,timeseries[i],100,\"test2_6_2\")\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    #braccio_dx.append(IgnoreZone(i,np.array(MajorityVoteCP(cp,100,j)).astype(int),gt))\n",
    "       \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    #cp=IgnoreZone(i,cp,gt)\n",
    "    #cp=delnear(cp,100)\n",
    "\n",
    "      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
