{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tikyn\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\aeon\\base\\__init__.py:24: FutureWarning: The aeon package will soon be releasing v1.0.0 with the removal of legacy modules and interfaces such as BaseTransformer and BaseForecaster. This will contain breaking changes. See aeon-toolkit.org for more information. Set aeon.AEON_DEPRECATION_WARNING or the AEON_DEPRECATION_WARNING environmental variable to 'False' to disable this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from claspy.segmentation import BinaryClaSPSegmentation\n",
    "\n",
    "import ruptures as rpt\n",
    "\n",
    "import stumpy\n",
    "from aeon.segmentation import find_dominant_window_sizes\n",
    "\n",
    "from aeon.segmentation import GreedyGaussianSegmenter\n",
    "\n",
    "from aeon.segmentation import InformationGainSegmenter\n",
    "\n",
    "from aeon.anomaly_detection import STRAY\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, make_scorer,mean_squared_error\n",
    "from ruptures.metrics import precision_recall\n",
    "import matplotlib.pyplot as plt\n",
    "#from aeon.visualisation import plot_series_with_change_points, plot_series_with_profiles\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()\n",
    "sns.set_color_codes()\n",
    "\n",
    "from claspy.tests.evaluation import f_measure,covering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1scoremargin(ground_truth, predictions, tolerance):\n",
    "    \"\"\"\n",
    "    Calcola l'F1 score con una finestra di tolleranza sui change points.\n",
    "    \n",
    "    :param ground_truth: Lista o array di change points reali\n",
    "    :param predictions: Lista o array di change points predetti\n",
    "    :param tolerance: La tolleranza temporale (numero di unità temporali)\n",
    "    :return: precision, recall, f1-score\n",
    "    \"\"\"\n",
    "    ground_truth = np.array(ground_truth)\n",
    "    predictions = np.array(predictions)\n",
    "    \n",
    "    # Vettori per tracciare quali punti sono stati già associati\n",
    "    matched_ground_truth = np.zeros(len(ground_truth), dtype=bool)\n",
    "    matched_predictions = np.zeros(len(predictions), dtype=bool)\n",
    "\n",
    "    mgt={key: False for key in ground_truth}\n",
    "    mcp={key: False for key in predictions}\n",
    "    #print(f'gt:{len(ground_truth)} - cp:{len(predictions)}')\n",
    "    # True Positives (TP)\n",
    "    tp = 0\n",
    "    for i, gt_point in enumerate(ground_truth):\n",
    "        for j, pred_point in enumerate(predictions):\n",
    "            if not matched_predictions[j] and abs(gt_point - pred_point) <= tolerance:\n",
    "                tp += 1\n",
    "                matched_ground_truth[i] = True\n",
    "                matched_predictions[j] = True\n",
    "\n",
    "                mgt[gt_point] = True\n",
    "                mcp[pred_point] = True\n",
    "                break\n",
    "            \n",
    "    \n",
    "    # False Positives (FP) - predizioni non corrispondenti a nessun ground truth entro la tolleranza\n",
    "    fp = np.sum(~matched_predictions)\n",
    "    \n",
    "    # False Negatives (FN) - punti del ground truth non corrispondenti a nessuna predizione entro la tolleranza\n",
    "    fn = np.sum(~matched_ground_truth)\n",
    "    #print(f'tp:{tp} - fp:{fp} - fn:{fn}')\n",
    "    #print(mgt)\n",
    "    #print(mcp)\n",
    "    # Calcolo di precision, recall e F1-score\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questi sono tutte le features estratte\n",
    "# kineticglobal,kineticchest,directnesshead,density,leftwristke,rightwristke,leftankleke,rightankleke,headke,posturaltension\n",
    "\n",
    "# Queste sono le feature che utilizzeremo\n",
    "# kineticglobal, density, leftwirstke, rightwristke, leftankleke, rightankleke, headke, posturaltension\n",
    "# che corrispondono\n",
    "# 2,4,5,6,7,8,9,10,11\n",
    "# Questa funzione legge il file di input e restituisce un dataframe con i dati preprocessati\n",
    "def ReadAndPreProcess(inputDataRaw):\n",
    "    # lettura\n",
    "    df=pd.read_csv(inputDataRaw,sep=' ', header=None)\n",
    "    df.drop(0, axis=1)\n",
    "    df[\"som\"]=df.sum(axis=1)\n",
    "    ## preprocessing\n",
    "\n",
    "    # dealing NaN values\n",
    "    #-serafino ha usato forward fill, backward fill, linear interpolation\n",
    "    #-ricordo che serafino aveva gia utilizzato sta cosa sui dati grezzi non sulle feature ma sui dati prefeature percio dovrebbe essere gia apposto\n",
    "\n",
    "    # downsampling\n",
    "    #-sono a 100ms, non sò se devo scendere a 50ms. da decidere\n",
    "    #-non lo faccio xk non mi interessa se va piu lento, guarda su notion per ulteriori informazioni\n",
    "\n",
    "    # low pass filter\n",
    "    #-Skogstad and colleagues (2013) e https://stackoverflow.com/questions/25191620/creating-lowpass-filter-in-scipy-understanding-methods-and-units\n",
    "    #-implementare dopo\n",
    "\n",
    "    # remove outliers\n",
    "    #-utilizzare hampel filter\n",
    "\n",
    "    # stretch\n",
    "    #-forse devo stretcharlo come ho fatto precedentemente\n",
    "    #-anche se nel codice precedente ho stretchato solo il groundtruth\n",
    "\n",
    "    # ritorno un oggetto dataframe dopo che è stato lavorato, ottenendo un prodotto lavorato\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questa funzione ritorna un dataframe del groundtruth che viene usato specificatamente per visualizzare il gt\n",
    "# è soggetto a un preprocessing dei dati siccome l'ultimo groundtruth è dove termina il ts del gt\n",
    "# di conseguenza per farlo corrispondere, bisogna stretcharlo\n",
    "# ma ricordo di aver rifatti i dati nuovi per generare un groundtruth a fine ts, da controllare cosi che non serve stretcharlo?\n",
    "def LoadingGroundTruth(df,gtraw):\n",
    "    gt=pd.read_csv(gtraw,sep=' ', header=None)\n",
    "    gt=gt.iloc[:,0].values\n",
    "    #stretching dei dati se necessario per farlo corrispondere alla ts dei dati\n",
    "    stretch_gt = np.array([])\n",
    "    for idx,i in enumerate(gt):\n",
    "        relpos = len(df)*i/gt[-1]\n",
    "        stretch_gt = np.append(stretch_gt,relpos)\n",
    "\n",
    "    # eliminiamo l'ultimo elemento che è stato annotato solo per delimitare la lunghezza della gt simile alla ts\n",
    "    return stretch_gt[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilizzo CLASP \n",
    "# prende come parametro un dataframe e restituisce il clasp score\n",
    "# gt e known vengono usati per usare il numero vero di cp se uguale a 1 sennò si cerca di predirlo se il modello lo permette\n",
    "def GetClasp(df,gt,known, **kwargs):\n",
    "    \n",
    "    result=np.array([])\n",
    "    eachresult = []\n",
    "    eachclasp=[]\n",
    "    for idx,i in enumerate([2,4,5,6,7,8,9,10,11]):\n",
    "      \n",
    "        ts=df.iloc[:,i]\n",
    "        clasp = BinaryClaSPSegmentation(**kwargs)\n",
    "        found_cps = clasp.fit_predict(ts.values)    \n",
    "\n",
    "        # c'è un bug con binseg dove un cp è oltre la lunghezza del ts\n",
    "        # faccio un loop e se eccede cambio il valore con la len(tf)-1\n",
    "        for i in range(0,len(found_cps)):\n",
    "            if found_cps[i] >= len(ts):\n",
    "                found_cps[i] = len(ts)-1\n",
    "\n",
    "        # per ogni array di cp di ogni singola feature\n",
    "        # li unisco in un unico array. in pratica faccio un OR di tutti i cp\n",
    "        result = np.sort(np.append(result,found_cps).flatten())\n",
    "        result = np.unique(result)\n",
    "        eachresult.append(found_cps)\n",
    "        eachclasp.append(clasp)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    return result, eachresult, eachclasp\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcola i vari scores dati il groundtruth e il prediction\n",
    "# puo salvare il risultato su file per evitare di perderli\n",
    "# prende come parametro nome del groundtruth, groundtruth, nome della timeseries e il prediction\n",
    "def Evaluate(modelName,gtName, gt, tsName, cp, df, margin,msg, nomeFile):\n",
    "    # creo dei array di lunghezza come la ts cosi possono fare il confronto\n",
    "    # sia per il gt che per il pd\n",
    "  \n",
    "    cpnump = np.array(cp)\n",
    "    gtnump = np.array(gt)\n",
    "\n",
    "    cp_long = np.zeros(len(df)+1)\n",
    "    cp_long[cpnump.astype(int)]=1\n",
    "\n",
    "    gt_long = np.zeros(len(df)+1)\n",
    "    gt_long[gtnump.astype(int)]=1\n",
    "\n",
    "    # calcolo lo score \n",
    "    print(f'f1margin: {f1scoremargin(gt.astype(int),cp.astype(int),margin)}')\n",
    "    precision,recall,f1=f1scoremargin(gt.astype(int),cp.astype(int),margin)\n",
    "\n",
    "    return precision,recall,f1\n",
    "     #scrivo su file il risultato\n",
    "\n",
    "    \"\"\"\n",
    "    f = open(\"outputFile/ClaSPallresult\", \"a\")\n",
    "    f.write(nomeFile+\"\\n\")\n",
    "    f.write(msg+\"\\n\")\n",
    "    f.write(\"precision:\"+str(precision)+\" recall:\"+str(recall)+\" f1:\"+str(f1)+\" \\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.close()\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plotclasp(eachclasp,gt,margin,eachcp,nomeFile):\n",
    "    \n",
    "    for idx,clasp in enumerate(eachclasp):\n",
    "        clasp.plot(gt_cps=gt.astype(int), heading=f'f1margin: {f1scoremargin(gt.astype(int),eachcp[idx].astype(int),margin)} {nomeFile}', ts_name=\"suss\", file_path=\"segmentation_example.png\")\n",
    "\n",
    "\n",
    "    \n",
    "        for idx2,j in enumerate(gt.astype(int)):\n",
    "            plt.fill_betweenx(np.array([0, 1]), j-margin, j+margin, color='green', alpha=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotResult(df,gt,cp, nomeFile, margin):\n",
    "    #da testare quando ho piu valori\n",
    "    #clasp.plot(gt_cps=gt.astype(int), heading=\"Segmentation of different umpire cricket signals\", ts_name=\"ACC\", file_path=\"segmentation_example.png\")\n",
    "\n",
    "    plt.figure(figsize=(18,9))\n",
    "    plt.plot(np.arange(len(df[\"som\"].values)),df[\"som\"].values,'blue',linewidth=0.5)\n",
    "    for idx2,i in enumerate(gt.astype(int)):\n",
    "\n",
    "            plt.axvline(x = i, color = 'green',linewidth=1) \n",
    "            \n",
    "    for j in cp.tolist():\n",
    "        plt.axvline(x = j, color = 'red',linewidth=1,linestyle=\"-.\") \n",
    "\n",
    "    for idx2,k in enumerate(gt.astype(int)):\n",
    "            plt.fill_betweenx(np.array([0, 1]), k-margin, k+margin, color='green', alpha=0.3)\n",
    "    plt.xlabel(f'{nomeFile} {f1scoremargin(gt.astype(int),cp.astype(int),margin)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries=[\n",
    "    \"in\\cora1_input.txt\",\n",
    "      \"in\\cora4_input.txt\",\n",
    "      \"in\\cora5_input.txt\",\n",
    "      \"in\\cora14_input.txt\",\n",
    "      \"in\\marianne7_input.txt\",\n",
    "      \"in\\marianne8_input.txt\",\n",
    "      \"in\\marianne10_input.txt\",\n",
    "      \"in\\marianne18_input.txt\",\n",
    "      \"in\\marianne19_input.txt\",\n",
    "      \"in\\marianne24_input.txt\",\n",
    "      \"in\\marianne26_input.txt\",\n",
    "      \"in\\marianne41_input.txt\",\n",
    "      \"in\\marianne42_input.txt\",\n",
    "      \"in\\marianne43_input.txt\",\n",
    "      \"in\\marianne47_input.txt\",\n",
    "      \"in\\marianne48_input.txt\",\n",
    "      \"in\\muriel18_input.txt\",\n",
    "      \"in\\muriel26_input.txt\",\n",
    "      \"in\\muriel27_input.txt\",\n",
    "      \"in\\muriel30_input.txt\"\n",
    "\n",
    "      ]\n",
    "groundtruth=[\n",
    "         \"gt\\cora_gt_2019-08-08_t001_video01.txt\",\n",
    "         \"gt\\cora_gt_2019-08-08_t004_video01.txt\",\n",
    "         \"gt\\cora5_gt.txt\",\n",
    "         \"gt\\cora_gt_2019-08-08_t014_video01.txt\",\n",
    "         \"gt\\marianne_gt_2016-03-22_t007_video01.txt\",\n",
    "         \"gt\\marianne_gt_2016-03-22_t008_video01.txt\",\n",
    "         \"gt\\marianne_gt_2016-03-22_t010_video01.txt\",\n",
    "         \"gt\\marianne_gt_2016-03-22_t018_video01.txt\",\n",
    "         \"gt\\marianne_gt_2016-03-22_t019_video01.txt\",\n",
    "         \"gt\\marianne_gt_2016-03-22_t024_video01.txt\",\n",
    "         \"gt\\marianne_gt_2016-03-22_t026_video01.txt\",\n",
    "         \"gt\\marianne_gt_2016-03-22_t041_video01.txt\",\n",
    "         \"gt\\marianne_gt_2016-03-22_t042_video01.txt\",\n",
    "         \"gt\\marianne_gt_2016-03-22_t043_video01.txt\",\n",
    "         \"gt\\marianne_gt_2016-03-22_t047_video01.txt\",\n",
    "         \"gt\\marianne_gt_2016-03-22_t048_video01.txt\",\n",
    "         \"gt\\muriel_gt_2016-03-21_t018_video01.txt\",\n",
    "         \"gt\\muriel_gt_2016-03-21_t026_video01.txt\",\n",
    "         \"gt\\muriel_gt_2016-03-21_t027_video01.txt\",\n",
    "         \"gt\\muriel_gt_2016-03-23_t030_video01.txt\"\n",
    "         ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "f1margin: (0.34615384615384615, 0.28125, 0.3103448275862069)\n",
      "1\n",
      "f1margin: (0.4444444444444444, 0.25, 0.32)\n",
      "2\n",
      "f1margin: (0.1728395061728395, 0.8235294117647058, 0.2857142857142857)\n",
      "3\n",
      "f1margin: (1.0, 0.04, 0.07692307692307693)\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tikyn\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\stats\\_stats_py.py:9205: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  z = (s - expected) / np.sqrt(n1*n2*(n1+n2+1)/12.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1margin: (0.16666666666666666, 0.047619047619047616, 0.07407407407407407)\n",
      "5\n",
      "f1margin: (1.0, 0.07407407407407407, 0.13793103448275862)\n",
      "6\n",
      "f1margin: (1.0, 0.07692307692307693, 0.14285714285714288)\n",
      "7\n",
      "f1margin: (0.5, 0.038461538461538464, 0.07142857142857144)\n",
      "8\n",
      "f1margin: (1.0, 0.06666666666666667, 0.125)\n",
      "9\n",
      "f1margin: (1.0, 0.045454545454545456, 0.08695652173913045)\n",
      "10\n",
      "f1margin: (0, 0.0, 0)\n",
      "11\n",
      "f1margin: (0.5, 0.07692307692307693, 0.13333333333333336)\n",
      "12\n",
      "f1margin: (0.0, 0.0, 0)\n",
      "13\n",
      "f1margin: (0.2631578947368421, 0.1282051282051282, 0.17241379310344826)\n",
      "14\n",
      "f1margin: (0, 0.0, 0)\n",
      "15\n",
      "f1margin: (1.0, 0.058823529411764705, 0.1111111111111111)\n",
      "16\n",
      "f1margin: (1.0, 0.08571428571428572, 0.15789473684210528)\n",
      "17\n",
      "f1margin: (0.0, 0.0, 0)\n",
      "18\n",
      "f1margin: (1.0, 0.012658227848101266, 0.024999999999999998)\n",
      "19\n",
      "f1margin: (0.6363636363636364, 0.18421052631578946, 0.2857142857142857)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#fft\\nouteval=[]\\nfor i in range(len(timeseries)):\\n    print(i)\\n    df=ReadAndPreProcess(timeseries[i])\\n    gt=LoadingGroundTruth(df,groundtruth[i])\\n    cp,eachcp,clasp=GetClasp(df,gt,0,window_size=\"fft\")\\n    #PlotResult(df,gt,cp, timeseries[i], 100)\\n    precision,recall,f1=Evaluate(\"CLASP\",groundtruth[i],gt,timeseries[i],cp,df,100,\"fft\",timeseries[i])\\noutdf[\"fft\"] = outeval\\n\\n#acf\\nouteval=[]\\nfor i in range(len(timeseries)):\\n    print(i)\\n    df=ReadAndPreProcess(timeseries[i])\\n    gt=LoadingGroundTruth(df,groundtruth[i])\\n    cp,eachcp,clasp=GetClasp(df,gt,0,window_size=\"acf\")\\n    #PlotResult(df,gt,cp, timeseries[i], 100)\\n    precision,recall,f1=Evaluate(\"CLASP\",groundtruth[i],gt,timeseries[i],cp,df,100,\"acf\",timeseries[i])\\noutdf[\"acf\"] = outeval\\n\\n#suss, euclidean\\nouteval=[]\\nfor i in range(len(timeseries)):\\n    print(i)\\n    df=ReadAndPreProcess(timeseries[i])\\n    gt=LoadingGroundTruth(df,groundtruth[i])\\n    cp,eachcp,clasp=GetClasp(df,gt,0,window_size=\"suss\", distance=\"euclidean_distance\")\\n    #PlotResult(df,gt,cp, timeseries[i], 100)\\n    precision,recall,f1=Evaluate(\"CLASP\",groundtruth[i],gt,timeseries[i],cp,df,100,\"suss euclidean\",timeseries[i])\\noutdf[\"suss_euclidean\"] = outeval\\n\\n#fft, euclidean\\nouteval=[]\\nfor i in range(len(timeseries)):\\n    print(i)\\n    df=ReadAndPreProcess(timeseries[i])\\n    gt=LoadingGroundTruth(df,groundtruth[i])\\n    cp,eachcp,clasp=GetClasp(df,gt,0,window_size=\"fft\", distance=\"euclidean_distance\")\\n    #PlotResult(df,gt,cp, timeseries[i], 100)\\n    precision,recall,f1=Evaluate(\"CLASP\",groundtruth[i],gt,timeseries[i],cp,df,100,\"fft euclidean\",timeseries[i])\\noutdf[\"fft_euclidean\"] = outeval\\n\\n#acf, euclidean\\nouteval=[]\\nfor i in range(len(timeseries)):\\n    print(i)\\n    df=ReadAndPreProcess(timeseries[i])\\n    gt=LoadingGroundTruth(df,groundtruth[i])\\n    cp,eachcp,clasp=GetClasp(df,gt,0,window_size=\"acf\", distance=\"euclidean_distance\")\\n    #PlotResult(df,gt,cp, timeseries[i], 100)\\n    precision,recall,f1=Evaluate(\"CLASP\",groundtruth[i],gt,timeseries[i],cp,df,100,\"acf euclidean\",timeseries[i])\\noutdf[\"acf_euclidean\"] = outeval\\n\\n#suss, euclidean, 4\\nouteval=[]\\nfor i in range(len(timeseries)):\\n    print(i)\\n    df=ReadAndPreProcess(timeseries[i])\\n    gt=LoadingGroundTruth(df,groundtruth[i])\\n    cp,eachcp,clasp=GetClasp(df,gt,0,window_size=\"suss\", distance=\"euclidean_distance\", excl_radius=4)\\n    #PlotResult(df,gt,cp, timeseries[i], 100)\\n    precision,recall,f1=Evaluate(\"CLASP\",groundtruth[i],gt,timeseries[i],cp,df,100,\"suss euclidean 4\",timeseries[i])\\noutdf[\"suss_euclidean_4\"] = outeval\\n\\n#fft, euclidean, 4\\nouteval=[]\\nfor i in range(len(timeseries)):\\n    print(i)\\n    df=ReadAndPreProcess(timeseries[i])\\n    gt=LoadingGroundTruth(df,groundtruth[i])\\n    cp,eachcp,clasp=GetClasp(df,gt,0,window_size=\"fft\", distance=\"euclidean_distance\", excl_radius=4)\\n    #PlotResult(df,gt,cp, timeseries[i], 100)\\n    precision,recall,f1=Evaluate(\"CLASP\",groundtruth[i],gt,timeseries[i],cp,df,100,\"fft euclidean 4\",timeseries[i])\\noutdf[\"fft_euclidean_4\"] = outeval\\n\\n#acf, euclidean, 4\\nouteval=[]\\nfor i in range(len(timeseries)):\\n    print(i)\\n    df=ReadAndPreProcess(timeseries[i])\\n    gt=LoadingGroundTruth(df,groundtruth[i])\\n    cp,eachcp,clasp=GetClasp(df,gt,0,window_size=\"acf\", distance=\"euclidean_distance\", excl_radius=4)\\n    #PlotResult(df,gt,cp, timeseries[i], 100)\\n    precision,recall,f1=Evaluate(\"CLASP\",groundtruth[i],gt,timeseries[i],cp,df,100,\"acf euclidean 4\",timeseries[i])\\noutdf[\"acf_euclidean_4\"] = outeval\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_array = [s[3:-10] for s in timeseries]\n",
    "outdf = pd.DataFrame({\"name\":cleaned_array})\n",
    "\n",
    "\n",
    "# suss\n",
    "outeval=[]\n",
    "for i in range(len(timeseries)):\n",
    "    print(i)\n",
    "    df=ReadAndPreProcess(timeseries[i])\n",
    "    gt=LoadingGroundTruth(df,groundtruth[i])\n",
    "    cp,eachcp,clasp=GetClasp(df,gt,0,n_jobs=3)\n",
    "    #PlotResult(df,gt,cp, timeseries[i], 100)\n",
    "    precision,recall,f1=Evaluate(\"CLASP\",groundtruth[i],gt,timeseries[i],cp,df,100,\"suss\",timeseries[i])\n",
    "    outeval.append(f1)\n",
    "outdf[\"suss\"] = outeval\n",
    "\n",
    "\n",
    "\n",
    "#fft\n",
    "outeval=[]\n",
    "for i in range(len(timeseries)):\n",
    "    print(i)\n",
    "    df=ReadAndPreProcess(timeseries[i])\n",
    "    gt=LoadingGroundTruth(df,groundtruth[i])\n",
    "    cp,eachcp,clasp=GetClasp(df,gt,0,window_size=\"fft\")\n",
    "    #PlotResult(df,gt,cp, timeseries[i], 100)\n",
    "    precision,recall,f1=Evaluate(\"CLASP\",groundtruth[i],gt,timeseries[i],cp,df,100,\"fft\",timeseries[i])\n",
    "    outeval.append(f1)\n",
    "outdf[\"fft\"] = outeval\n",
    "\n",
    "#acf\n",
    "outeval=[]\n",
    "for i in range(len(timeseries)):\n",
    "    print(i)\n",
    "    df=ReadAndPreProcess(timeseries[i])\n",
    "    gt=LoadingGroundTruth(df,groundtruth[i])\n",
    "    cp,eachcp,clasp=GetClasp(df,gt,0,window_size=\"acf\")\n",
    "    #PlotResult(df,gt,cp, timeseries[i], 100)\n",
    "    precision,recall,f1=Evaluate(\"CLASP\",groundtruth[i],gt,timeseries[i],cp,df,100,\"acf\",timeseries[i])\n",
    "    outeval.append(f1)\n",
    "outdf[\"acf\"] = outeval\n",
    "\n",
    "#suss, euclidean\n",
    "outeval=[]\n",
    "for i in range(len(timeseries)):\n",
    "    print(i)\n",
    "    df=ReadAndPreProcess(timeseries[i])\n",
    "    gt=LoadingGroundTruth(df,groundtruth[i])\n",
    "    cp,eachcp,clasp=GetClasp(df,gt,0,window_size=\"suss\", distance=\"euclidean_distance\")\n",
    "    #PlotResult(df,gt,cp, timeseries[i], 100)\n",
    "    precision,recall,f1=Evaluate(\"CLASP\",groundtruth[i],gt,timeseries[i],cp,df,100,\"suss euclidean\",timeseries[i])\n",
    "    outeval.append(f1)\n",
    "outdf[\"suss_euclidean\"] = outeval\n",
    "\n",
    "#fft, euclidean\n",
    "outeval=[]\n",
    "for i in range(len(timeseries)):\n",
    "    print(i)\n",
    "    df=ReadAndPreProcess(timeseries[i])\n",
    "    gt=LoadingGroundTruth(df,groundtruth[i])\n",
    "    cp,eachcp,clasp=GetClasp(df,gt,0,window_size=\"fft\", distance=\"euclidean_distance\")\n",
    "    #PlotResult(df,gt,cp, timeseries[i], 100)\n",
    "    precision,recall,f1=Evaluate(\"CLASP\",groundtruth[i],gt,timeseries[i],cp,df,100,\"fft euclidean\",timeseries[i])\n",
    "    outeval.append(f1)\n",
    "outdf[\"fft_euclidean\"] = outeval\n",
    "\n",
    "#acf, euclidean\n",
    "outeval=[]\n",
    "for i in range(len(timeseries)):\n",
    "    print(i)\n",
    "    df=ReadAndPreProcess(timeseries[i])\n",
    "    gt=LoadingGroundTruth(df,groundtruth[i])\n",
    "    cp,eachcp,clasp=GetClasp(df,gt,0,window_size=\"acf\", distance=\"euclidean_distance\")\n",
    "    #PlotResult(df,gt,cp, timeseries[i], 100)\n",
    "    precision,recall,f1=Evaluate(\"CLASP\",groundtruth[i],gt,timeseries[i],cp,df,100,\"acf euclidean\",timeseries[i])\n",
    "    outeval.append(f1)\n",
    "outdf[\"acf_euclidean\"] = outeval\n",
    "\n",
    "#suss, euclidean, 4\n",
    "outeval=[]\n",
    "for i in range(len(timeseries)):\n",
    "    print(i)\n",
    "    df=ReadAndPreProcess(timeseries[i])\n",
    "    gt=LoadingGroundTruth(df,groundtruth[i])\n",
    "    cp,eachcp,clasp=GetClasp(df,gt,0,window_size=\"suss\", distance=\"euclidean_distance\", excl_radius=4)\n",
    "    #PlotResult(df,gt,cp, timeseries[i], 100)\n",
    "    precision,recall,f1=Evaluate(\"CLASP\",groundtruth[i],gt,timeseries[i],cp,df,100,\"suss euclidean 4\",timeseries[i])\n",
    "    outeval.append(f1)\n",
    "outdf[\"suss_euclidean_4\"] = outeval\n",
    "\n",
    "#fft, euclidean, 4\n",
    "outeval=[]\n",
    "for i in range(len(timeseries)):\n",
    "    print(i)\n",
    "    df=ReadAndPreProcess(timeseries[i])\n",
    "    gt=LoadingGroundTruth(df,groundtruth[i])\n",
    "    cp,eachcp,clasp=GetClasp(df,gt,0,window_size=\"fft\", distance=\"euclidean_distance\", excl_radius=4)\n",
    "    #PlotResult(df,gt,cp, timeseries[i], 100)\n",
    "    precision,recall,f1=Evaluate(\"CLASP\",groundtruth[i],gt,timeseries[i],cp,df,100,\"fft euclidean 4\",timeseries[i])\n",
    "    outeval.append(f1)\n",
    "outdf[\"fft_euclidean_4\"] = outeval\n",
    "\n",
    "#acf, euclidean, 4\n",
    "outeval=[]\n",
    "for i in range(len(timeseries)):\n",
    "    print(i)\n",
    "    df=ReadAndPreProcess(timeseries[i])\n",
    "    gt=LoadingGroundTruth(df,groundtruth[i])\n",
    "    cp,eachcp,clasp=GetClasp(df,gt,0,window_size=\"acf\", distance=\"euclidean_distance\", excl_radius=4)\n",
    "    #PlotResult(df,gt,cp, timeseries[i], 100)\n",
    "    precision,recall,f1=Evaluate(\"CLASP\",groundtruth[i],gt,timeseries[i],cp,df,100,\"acf euclidean 4\",timeseries[i])\n",
    "    outeval.append(f1)\n",
    "outdf[\"acf_euclidean_4\"] = outeval\n",
    "outdf.to_excel(\"outputFile/outputnocpknown.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
