{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tikyn\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\aeon\\base\\__init__.py:24: FutureWarning: The aeon package will soon be releasing v1.0.0 with the removal of legacy modules and interfaces such as BaseTransformer and BaseForecaster. This will contain breaking changes. See aeon-toolkit.org for more information. Set aeon.AEON_DEPRECATION_WARNING or the AEON_DEPRECATION_WARNING environmental variable to 'False' to disable this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from claspy.segmentation import BinaryClaSPSegmentation\n",
    "\n",
    "import ruptures as rpt\n",
    "\n",
    "import stumpy\n",
    "from aeon.segmentation import find_dominant_window_sizes\n",
    "\n",
    "from aeon.segmentation import GreedyGaussianSegmenter\n",
    "\n",
    "from aeon.segmentation import InformationGainSegmenter\n",
    "\n",
    "from aeon.anomaly_detection import STRAY\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, make_scorer,mean_squared_error\n",
    "from ruptures.metrics import precision_recall\n",
    "import matplotlib.pyplot as plt\n",
    "#from aeon.visualisation import plot_series_with_change_points, plot_series_with_profiles\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()\n",
    "sns.set_color_codes()\n",
    "\n",
    "from claspy.tests.evaluation import f_measure,covering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IgnoreZone(idx,cpraw):\n",
    "    cp = cpraw.tolist()\n",
    "    if idx == 0:\n",
    "        for i in range(len(cp)-1, -1, -1):\n",
    "            if cp[i] > 3944.7118557910376+100 and cp[i] < 5911.693516853054-100 or cp[i] > 12845.0+100:\n",
    "                cp.pop(i)\n",
    "                \n",
    "        \n",
    "    elif idx == 1:\n",
    "        for i in range(len(cp)-1, -1, -1):\n",
    "            if cp[i] > 2874.607407407407+100 and cp[i] < 4016.935849056604-100:\n",
    "                cp.pop(i)\n",
    "\n",
    "    elif idx == 16:\n",
    "        for i in range(len(cp)-1, -1, -1):\n",
    "            if cp[i] > 180.03455207940698+100 and cp[i] < 1227.051137077522-100 or cp[i] > 5865.505591154668+100:\n",
    "                cp.pop(i)\n",
    "\n",
    "    elif idx == 17:\n",
    "        for i in range(len(cp)-1, -1, -1):\n",
    "            if cp[i] > 138.33224102186853+100 and cp[i] < 3677.231833076974-100:\n",
    "                cp.pop(i)\n",
    "\n",
    "\n",
    "    elif idx == 19:\n",
    "        for i in range(len(cp)-1, -1, -1):\n",
    "            if cp[i] > 8187.634803581529+100:\n",
    "                cp.pop(i)\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(\"error IgnoreZone()\")\n",
    "    return np.array(cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delnear(arr,range):\n",
    "    i = 0\n",
    "    while i < len(arr) - 1:\n",
    "        # Iniziamo con il primo elemento di un potenziale gruppo\n",
    "        gruppo_inizio = i\n",
    "        gruppo_fine = i\n",
    "\n",
    "        # Cerca gli elementi che fanno parte dello stesso gruppo\n",
    "        while gruppo_fine < len(arr) - 1 and arr[gruppo_fine + 1] - arr[gruppo_fine] < range:\n",
    "            gruppo_fine += 1\n",
    "\n",
    "        # Se esiste un gruppo di più elementi\n",
    "        if gruppo_fine > gruppo_inizio:\n",
    "            # Se la distanza tra l'inizio e la fine è minore di 50, elimina l'elemento maggiore (gruppo_fine)\n",
    "            if arr[gruppo_fine] - arr[gruppo_inizio] < range:\n",
    "                arr = np.delete(arr, gruppo_fine)\n",
    "            \n",
    "            # Elimina tutti gli elementi interni al gruppo\n",
    "            arr = np.concatenate((arr[:gruppo_inizio + 1], arr[gruppo_fine:]))\n",
    "\n",
    "        # Procedi con il prossimo gruppo\n",
    "        i = gruppo_inizio + 1\n",
    "\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1scoremargin(ground_truth, predictions, tolerance):\n",
    "    \"\"\"\n",
    "    Calcola l'F1 score con una finestra di tolleranza sui change points.\n",
    "    \n",
    "    :param ground_truth: Lista o array di change points reali\n",
    "    :param predictions: Lista o array di change points predetti\n",
    "    :param tolerance: La tolleranza temporale (numero di unità temporali)\n",
    "    :return: precision, recall, f1-score\n",
    "    \"\"\"\n",
    "    ground_truth = np.array(ground_truth)\n",
    "    predictions = np.array(predictions)\n",
    "    \n",
    "    # Vettori per tracciare quali punti sono stati già associati\n",
    "    matched_ground_truth = np.zeros(len(ground_truth), dtype=bool)\n",
    "    matched_predictions = np.zeros(len(predictions), dtype=bool)\n",
    "\n",
    "    mgt={key: False for key in ground_truth}\n",
    "    mcp={key: False for key in predictions}\n",
    "    #print(f'gt:{len(ground_truth)} - cp:{len(predictions)}')\n",
    "    # True Positives (TP)\n",
    "    tp = 0\n",
    "    for i, gt_point in enumerate(ground_truth):\n",
    "        for j, pred_point in enumerate(predictions):\n",
    "            if not matched_predictions[j] and abs(gt_point - pred_point) <= tolerance:\n",
    "                tp += 1\n",
    "                matched_ground_truth[i] = True\n",
    "                matched_predictions[j] = True\n",
    "\n",
    "                mgt[gt_point] = True\n",
    "                mcp[pred_point] = True\n",
    "                break\n",
    "            \n",
    "    \n",
    "    # False Positives (FP) - predizioni non corrispondenti a nessun ground truth entro la tolleranza\n",
    "    fp = np.sum(~matched_predictions)\n",
    "    \n",
    "    # False Negatives (FN) - punti del ground truth non corrispondenti a nessuna predizione entro la tolleranza\n",
    "    fn = np.sum(~matched_ground_truth)\n",
    "    #print(f'tp:{tp} - fp:{fp} - fn:{fn}')\n",
    "    #print(mgt)\n",
    "    #print(mcp)\n",
    "    # Calcolo di precision, recall e F1-score\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1, tp, fp, fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracted features. Use the index of this list to use with iloc[]\n",
    "<ol start=\"0\">\n",
    "  <li>Kinetic Global</li>\n",
    "  <li>Kinetic Chest</li>\n",
    "  <li>Directness Head</li>\n",
    "  <li>Density</li>\n",
    "  <li>left wrist ke</li>\n",
    "  <li>right wrist ke</li>\n",
    "  <li>left ankle ke</li>\n",
    "  <li>right ankle ke</li>\n",
    "  <li>head ke</li>\n",
    "  <li>crouch density</li>\n",
    "  <li>left leg density</li>\n",
    "  <li>right leg density</li>\n",
    "  <li>left hand density</li>\n",
    "  <li>right hand density</li>\n",
    "  <li>hand density</li>\n",
    "  <li>arto inferiore</li>\n",
    "  <li>gamba</li>\n",
    "  <li>coscia</li>\n",
    "  <li>coscia dx</li>\n",
    "  <li>coscia sx</li>\n",
    "  <li>gamba sx</li>\n",
    "  <li>gamba dx</li>\n",
    "  <li>braccio sx</li>\n",
    "  <li>braccio dx</li>\n",
    "  <li>avambraccio sx</li>\n",
    "  <li>avambraccio dx</li>\n",
    "  <li>ARIEL speed magnitude</li>\n",
    "  <li>ARIEL speed X component</li>\n",
    "  <li>ARIEL speed Y component</li>\n",
    "  <li>ARIEL speed Z component</li>\n",
    "  <li>ARIEL acceleration magnitude</li>\n",
    "  <li>ARIEL acceleration X component</li>\n",
    "  <li>ARIEL acceleration Y component</li>\n",
    "  <li>ARIEL acceleration Z component</li>\n",
    "  <li>ARIEL jerk magnitude</li>\n",
    "  <li>ARIEL jerk X component</li>\n",
    "  <li>ARIEL jerk Y component</li>\n",
    "  <li>ARIEL jerk Z component</li>\n",
    "  <li>STRN speed magnitude</li>\n",
    "  <li>STRN speed X component</li>\n",
    "  <li>STRN speed Y component</li>\n",
    "  <li>STRN speed Z component</li>\n",
    "  <li>STRN acceleration magnitude</li>\n",
    "  <li>STRN acceleration X component</li>\n",
    "  <li>STRN acceleration Y component</li>\n",
    "  <li>STRN accelerationZ component</li>\n",
    "  <li>STRN jerk magnitude</li>\n",
    "  <li>STRN jerk X component</li>\n",
    "  <li>STRN jerk Y component</li>\n",
    "  <li>STRN jerk Z component</li>\n",
    "  <li>RHEL speed magnitude</li>\n",
    "  <li>RHEL speed X component</li>\n",
    "  <li>RHEL speed Y component</li>\n",
    "  <li>RHEL speed Z component</li>\n",
    "  <li>RHEL acceleration magnitude</li>\n",
    "  <li>RHEL acceleration X component</li>\n",
    "  <li>RHEL acceleration Y component</li>\n",
    "  <li>RHEL acceleration Z component</li>\n",
    "  <li>RHEL jerk magnitude</li>\n",
    "  <li>RHEL jerk X component</li>\n",
    "  <li>RHEL jerk Y component</li>\n",
    "  <li>RHEL jerk Z component</li>\n",
    "  <li>LHEL speed magnitude</li>\n",
    "  <li>LHEL speed X component</li>\n",
    "  <li>LHEL speed Y component</li>\n",
    "  <li>LHEL speed Z component</li>\n",
    "  <li>LHEL acceleration magnitude</li>\n",
    "  <li>LHEL acceleration X component</li>\n",
    "  <li>LHEL acceleration Y component</li>\n",
    "  <li>LHEL acceleration Z component</li>\n",
    "  <li>LHEL jerk magnitude</li>\n",
    "  <li>LHEL jerk X component</li>\n",
    "  <li>LHEL jerk Y component</li>\n",
    "  <li>LHEL jerk Z component</li>\n",
    "  <li>RPLM speed magnitude</li>\n",
    "  <li>RPLM speed X component</li>\n",
    "  <li>RPLM speed Y component</li>\n",
    "  <li>RPLM speed Z component</li>\n",
    "  <li>RPLM acceleration magnitude</li>\n",
    "  <li>RPLM acceleration X component</li>\n",
    "  <li>RPLM acceleration Y component</li>\n",
    "  <li>RPLM acceleration Z component</li>\n",
    "  <li>RPLM jerk magnitude</li>\n",
    "  <li>RPLM jerk X component</li>\n",
    "  <li>RPLM jerk Y component</li>\n",
    "  <li>RPLM jerk Z component</li>\n",
    "  <li>LPLM speed magnitude</li>\n",
    "  <li>LPLM speed X component</li>\n",
    "  <li>LPLM speed Y component</li>\n",
    "  <li>LPLM speed Z component</li>\n",
    "  <li>LPLM acceleration magnitude</li>\n",
    "  <li>LPLM acceleration X component</li>\n",
    "  <li>LPLM acceleration Y component</li>\n",
    "  <li>LPLM acceleration Z component</li>\n",
    "  <li>LPLM jerk magnitude</li>\n",
    "  <li>LPLM jerk X component</li>\n",
    "  <li>LPLM jerk Y component</li>\n",
    "  <li>LPLM jerk Z component</li>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of features. To access its name or its value while using iloc\n",
    "features_name=[\n",
    "    \"kinetic_global\",\n",
    "    \"kinetic_chest\",\n",
    "    \"directness_head\",\n",
    "    \"density\",\n",
    "    \"left_wrist_ke\",\n",
    "    \"right_wrist_ke\",\n",
    "    \"left_ankle_ke\",\n",
    "    \"right_ankle_ke\",\n",
    "    \"head_ke\",\n",
    "    \"crouch_density\",\n",
    "    \"left_leg_density\",\n",
    "    \"right_leg_density\",\n",
    "    \"left_hand_density\",\n",
    "    \"right_hand_density\",\n",
    "    \"hand_density\",\n",
    "    \"arto_inferiore\",\n",
    "    \"gamba\",\n",
    "    \"coscia\",\n",
    "    \"coscia_dx\",\n",
    "    \"coscia_sx\",\n",
    "    \"gamba_sx\",\n",
    "    \"gamba_dx\",\n",
    "    \"braccio_sx\",\n",
    "    \"braccio_dx\",\n",
    "    \"avambraccio_sx\",\n",
    "    \"avambraccio_dx\",\n",
    "    \"ARIEL_speed_magnitude\",\n",
    "    \"ARIEL_speed_X_component\",\n",
    "    \"ARIEL_speed_Y_component\",\n",
    "    \"ARIEL_speed_Z_component\",\n",
    "    \"ARIEL_acceleration_magnitude\",\n",
    "    \"ARIEL_acceleration_X_component\",\n",
    "    \"ARIEL_acceleration_Y_component\",\n",
    "    \"ARIEL_acceleration_Z_component\",\n",
    "    \"ARIEL_jerk_magnitude\",\n",
    "    \"ARIEL_jerk_X_component\",\n",
    "    \"ARIEL_jerk_Y_component\",\n",
    "    \"ARIEL_jerk_Z_component\",\n",
    "    \"STRN_speed_magnitude\",\n",
    "    \"STRN_speed_X_component\",\n",
    "    \"STRN_speed_Y_component\",\n",
    "    \"STRN_speed_Z_component\",\n",
    "    \"STRN_acceleration_magnitude\",\n",
    "    \"STRN_acceleration_X_component\",\n",
    "    \"STRN_acceleration_Y_component\",\n",
    "    \"STRN_acceleration_Z_component\",\n",
    "    \"STRN_jerk_magnitude\",\n",
    "    \"STRN_jerk_X_component\",\n",
    "    \"STRN_jerk_Y_component\",\n",
    "    \"STRN_jerk_Z_component\",\n",
    "    \"RHEL_speed_magnitude\",\n",
    "    \"RHEL_speed_X_component\",\n",
    "    \"RHEL_speed_Y_component\",\n",
    "    \"RHEL_speed_Z_component\",\n",
    "    \"RHEL_acceleration_magnitude\",\n",
    "    \"RHEL_acceleration_X_component\",\n",
    "    \"RHEL_acceleration_Y_component\",\n",
    "    \"RHEL_acceleration_Z_component\",\n",
    "    \"RHEL_jerk_magnitude\",\n",
    "    \"RHEL_jerk_X_component\",\n",
    "    \"RHEL_jerk_Y_component\",\n",
    "    \"RHEL_jerk_Z_component\",\n",
    "    \"LHEL_speed_magnitude\",\n",
    "    \"LHEL_speed_X_component\",\n",
    "    \"LHEL_speed_Y_component\",\n",
    "    \"LHEL_speed_Z_component\",\n",
    "    \"LHEL_acceleration_magnitude\",\n",
    "    \"LHEL_acceleration_X_component\",\n",
    "    \"LHEL_acceleration_Y_component\",\n",
    "    \"LHEL_acceleration_Z_component\",\n",
    "    \"LHEL_jerk_magnitude\",\n",
    "    \"LHEL_jerk_X_component\",\n",
    "    \"LHEL_jerk_Y_component\",\n",
    "    \"LHEL_jerk_Z_component\",\n",
    "    \"RPLM_speed_magnitude\",\n",
    "    \"RPLM_speed_X_component\",\n",
    "    \"RPLM_speed_Y_component\",\n",
    "    \"RPLM_speed_Z_component\",\n",
    "    \"RPLM_acceleration_magnitude\",\n",
    "    \"RPLM_acceleration_X_component\",\n",
    "    \"RPLM_acceleration_Y_component\",\n",
    "    \"RPLM_acceleration_Z_component\",\n",
    "    \"RPLM_jerk_magnitude\",\n",
    "    \"RPLM_jerk_X_component\",\n",
    "    \"RPLM_jerk_Y_component\",\n",
    "    \"RPLM_jerk_Z_component\",\n",
    "    \"LPLM_speed_magnitude\",\n",
    "    \"LPLM_speed_X_component\",\n",
    "    \"LPLM_speed_Y_component\",\n",
    "    \"LPLM_speed_Z_component\",\n",
    "    \"LPLM_acceleration_magnitude\",\n",
    "    \"LPLM_acceleration_X_component\",\n",
    "    \"LPLM_acceleration_Y_component\",\n",
    "    \"LPLM_acceleration_Z_component\",\n",
    "    \"LPLM_jerk_magnitude\",\n",
    "    \"LPLM_jerk_X_component\",\n",
    "    \"LPLM_jerk_Y_component\",\n",
    "    \"LPLM_jerk_Z_component\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questi sono tutte le features estratte\n",
    "# kineticglobal,kineticchest,directnesshead,density,leftwristke,rightwristke,leftankleke,rightankleke,headke,posturaltension\n",
    "\n",
    "# Queste sono le feature che utilizzeremo\n",
    "# kineticglobal, density, leftwirstke, rightwristke, leftankleke, rightankleke, headke, posturaltension\n",
    "# che corrispondono\n",
    "# 2,4,5,6,7,8,9,10,11\n",
    "# Questa funzione legge il file di input e restituisce un dataframe con i dati preprocessati\n",
    "# ATTENZIONE\n",
    "# il motivo per cui 4 corrisponde a density, mentre in realtà è il 3 è perchè df.drop prima non cancellava\n",
    "# perciò il iloc[:,0] corrispondeva alla colonna time che era rimasta\n",
    "# iloc considera le colonne come array\n",
    "def ReadAndPreProcess(inputDataRaw):\n",
    "    # lettura\n",
    "    df=pd.read_csv(inputDataRaw,sep=' ', header=None)\n",
    "    df=df.drop(0, axis=1)\n",
    "    # i dati usciti da eyesweb hanno le feature inverse, qui le faccio rimettere nel ordine giusto\n",
    "    df = df.iloc[:, ::-1]\n",
    "    df[\"som\"]=df.sum(axis=1)\n",
    "    ## preprocessing\n",
    "\n",
    "    # dealing NaN values\n",
    "    #-serafino ha usato forward fill, backward fill, linear interpolation\n",
    "    #-ricordo che serafino aveva gia utilizzato sta cosa sui dati grezzi non sulle feature ma sui dati prefeature percio dovrebbe essere gia apposto\n",
    "\n",
    "    # downsampling\n",
    "    #-sono a 100ms, non sò se devo scendere a 50ms. da decidere\n",
    "    #-non lo faccio xk non mi interessa se va piu lento, guarda su notion per ulteriori informazioni\n",
    "\n",
    "    # low pass filter\n",
    "    #-Skogstad and colleagues (2013) e https://stackoverflow.com/questions/25191620/creating-lowpass-filter-in-scipy-understanding-methods-and-units\n",
    "    #-implementare dopo\n",
    "\n",
    "    # remove outliers\n",
    "    #-utilizzare hampel filter\n",
    "\n",
    "    # stretch\n",
    "    #-forse devo stretcharlo come ho fatto precedentemente\n",
    "    #-anche se nel codice precedente ho stretchato solo il groundtruth\n",
    "\n",
    "    # ritorno un oggetto dataframe dopo che è stato lavorato, ottenendo un prodotto lavorato\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questa funzione ritorna un dataframe del groundtruth che viene usato specificatamente per visualizzare il gt\n",
    "# è soggetto a un preprocessing dei dati siccome l'ultimo groundtruth è dove termina il ts del gt\n",
    "# di conseguenza per farlo corrispondere, bisogna stretcharlo\n",
    "# ma ricordo di aver rifatti i dati nuovi per generare un groundtruth a fine ts, da controllare cosi che non serve stretcharlo?\n",
    "def LoadingGroundTruth(df,gtraw):\n",
    "    gt=pd.read_csv(gtraw,sep=' ', header=None)\n",
    "    gt=gt.iloc[:,0].values\n",
    "    #stretching dei dati se necessario per farlo corrispondere alla ts dei dati\n",
    "    stretch_gt = np.array([])\n",
    "    for idx,i in enumerate(gt):\n",
    "        relpos = len(df)*i/gt[-1]\n",
    "        stretch_gt = np.append(stretch_gt,relpos)\n",
    "\n",
    "    # eliminiamo l'ultimo elemento cbhe è stato annotato solo per delimitare la lunghezza della gt simile alla ts\n",
    "    return stretch_gt[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetClasp(df,gt,known, **kwargs):\n",
    "    \n",
    "    result=np.array([])\n",
    "    eachresult = []\n",
    "    eachclasp=[]\n",
    "    for idx,i in enumerate(range(0,98)):\n",
    "      \n",
    "        ts=df.iloc[:,i]\n",
    "        clasp = BinaryClaSPSegmentation(**kwargs)\n",
    "        found_cps = clasp.fit_predict(ts.values)    \n",
    "\n",
    "        # c'è un bug con binseg dove un cp è oltre la lunghezza del ts\n",
    "        # faccio un loop e se eccede cambio il valore con la len(tf)-1\n",
    "        for i in range(0,len(found_cps)):\n",
    "            if found_cps[i] >= len(ts):\n",
    "                found_cps[i] = len(ts)-1\n",
    "\n",
    "        # per ogni array di cp di ogni singola feature\n",
    "        # li unisco in un unico array. in pratica faccio un OR di tutti i cp\n",
    "        result = np.sort(np.append(result,found_cps).flatten())\n",
    "        result = np.unique(result)\n",
    "        eachresult.append(found_cps)\n",
    "        eachclasp.append(clasp)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    return result, eachresult, eachclasp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilizzo CLASP \n",
    "# prende come parametro un dataframe e restituisce il clasp score\n",
    "# gt e known vengono usati per usare il numero vero di cp se uguale a 1 sennò si cerca di predirlo se il modello lo permette\n",
    "def GetClaspOld(df,gt,known, **kwargs):\n",
    "    \n",
    "    result=np.array([])\n",
    "    eachresult = []\n",
    "    eachclasp=[]\n",
    "    for idx,i in enumerate([1,3,4,5,6,7,8]):\n",
    "        print(f'siamo:{i}')\n",
    "        ts=df.iloc[:,i]\n",
    "        clasp = BinaryClaSPSegmentation(**kwargs)\n",
    "        found_cps = clasp.fit_predict(ts.values)    \n",
    "\n",
    "        # c'è un bug con binseg dove un cp è oltre la lunghezza del ts\n",
    "        # faccio un loop e se eccede cambio il valore con la len(tf)-1\n",
    "        for i in range(0,len(found_cps)):\n",
    "            if found_cps[i] >= len(ts):\n",
    "                found_cps[i] = len(ts)-1\n",
    "\n",
    "        # per ogni array di cp di ogni singola feature\n",
    "        # li unisco in un unico array. in pratica faccio un OR di tutti i cp\n",
    "        result = np.sort(np.append(result,found_cps).flatten())\n",
    "        result = np.unique(result)\n",
    "        eachresult.append(found_cps)\n",
    "        eachclasp.append(clasp)\n",
    "        \n",
    "        \n",
    "        \n",
    "    return result, eachresult, eachclasp\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcola i vari scores dati il groundtruth e il prediction\n",
    "# puo salvare il risultato su file per evitare di perderli\n",
    "# prende come parametro nome del groundtruth, groundtruth, nome della timeseries e il prediction\n",
    "def Evaluate(modelName,gtName, gt, tsName, cp, df, margin,msg, nomeFile):\n",
    "    # creo dei array di lunghezza come la ts cosi possono fare il confronto\n",
    "    # sia per il gt che per il pd\n",
    "  \n",
    "    cpnump = np.array(cp)\n",
    "    gtnump = np.array(gt)\n",
    "\n",
    "    cp_long = np.zeros(len(df)+1)\n",
    "    cp_long[cpnump.astype(int)]=1\n",
    "\n",
    "    gt_long = np.zeros(len(df)+1)\n",
    "    gt_long[gtnump.astype(int)]=1\n",
    "\n",
    "    # calcolo lo score \n",
    "    print(f'f1margin: {f1scoremargin(gt.astype(int),cp.astype(int),margin)}')\n",
    "    precision,recall,f1,tp,fp,fn=f1scoremargin(gt.astype(int),cp.astype(int),margin)\n",
    "\n",
    "    return precision,recall,f1\n",
    "     #scrivo su file il risultato\n",
    "\n",
    "    \"\"\"\n",
    "    f = open(\"outputFile/ClaSPallresult\", \"a\")\n",
    "    f.write(nomeFile+\"\\n\")\n",
    "    f.write(msg+\"\\n\")\n",
    "    f.write(\"precision:\"+str(precision)+\" recall:\"+str(recall)+\" f1:\"+str(f1)+\" \\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.close()\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EvaluateEvery(eachcp,gt,margin):\n",
    "    result=[]\n",
    "    resultratio=[]\n",
    "    \n",
    "    for idx,cp in enumerate(eachcp):\n",
    "        precision,recall,f1,tp,fp,fn=f1scoremargin(gt.astype(int),eachcp[idx].astype(int),margin)\n",
    "        result.append(f1)\n",
    "        resultratio.append(str(tp)+\"/\"+str(fp)+\"/\"+str(fn))\n",
    "    return result,resultratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plotclasp(eachclasp,gt,margin,eachcp,nomeFile):\n",
    "    \n",
    "    for idx,clasp in enumerate(eachclasp):\n",
    "        clasp.plot(gt_cps=gt.astype(int), heading=f'f1margin: {f1scoremargin(gt.astype(int),eachcp[idx].astype(int),margin)} {nomeFile}', ts_name=\"suss\", file_path=\"segmentation_example.png\")\n",
    "\n",
    "\n",
    "    \n",
    "        for idx2,j in enumerate(gt.astype(int)):\n",
    "            plt.fill_betweenx(np.array([0, 1]), j-margin, j+margin, color='green', alpha=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotResult(df,gt,cp, nomeFile, margin):\n",
    "    #da testare quando ho piu valori\n",
    "    #clasp.plot(gt_cps=gt.astype(int), heading=\"Segmentation of different umpire cricket signals\", ts_name=\"ACC\", file_path=\"segmentation_example.png\")\n",
    "\n",
    "    plt.figure(figsize=(18,9))\n",
    "    plt.plot(np.arange(len(df[\"som\"].values)),df[\"som\"].values,'blue',linewidth=0.5)\n",
    "    for idx2,i in enumerate(gt.astype(int)):\n",
    "\n",
    "            plt.axvline(x = i, color = 'green',linewidth=1) \n",
    "            \n",
    "    for j in cp.tolist():\n",
    "        plt.axvline(x = j, color = 'red',linewidth=1,linestyle=\"-.\") \n",
    "\n",
    "    for idx2,k in enumerate(gt.astype(int)):\n",
    "            plt.fill_betweenx(np.array([0, 1]), k-margin, k+margin, color='green', alpha=0.3)\n",
    "    plt.xlabel(f'{nomeFile} {f1scoremargin(gt.astype(int),cp.astype(int),margin)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries=[\n",
    "      \"in\\cora1_in.txt\",\n",
    "      \"in\\cora4_05_in.txt\",\n",
    "      \"in\\cora4_08_in.txt\",\n",
    "      \"in\\cora5_in.txt\",\n",
    "      \"in\\cora14_in.txt\",\n",
    "      \"in\\marianne7_in.txt\",\n",
    "      \"in\\marianne8_in.txt\",\n",
    "      \"in\\marianne10_in.txt\",\n",
    "      \"in\\marianne18_in.txt\",\n",
    "      \"in\\marianne19_in.txt\",\n",
    "      \"in\\marianne24_in.txt\",\n",
    "      \"in\\marianne26_in.txt\",\n",
    "      \"in\\marianne41_in.txt\",\n",
    "      \"in\\marianne42_in.txt\",\n",
    "      \"in\\marianne43_in.txt\",\n",
    "      \"in\\marianne47_in.txt\",\n",
    "      \"in\\marianne48_in.txt\",\n",
    "      \"in\\muriel18_in.txt\",\n",
    "      \"in\\muriel26_in.txt\",\n",
    "      \"in\\muriel27_in.txt\",\n",
    "      \"in\\muriel30_in.txt\"\n",
    "      ]\n",
    "groundtruth=[\n",
    "      \"gt\\cora_gt_2019-08-08_t001_video01.txt\",\n",
    "      \"gt\\cora_gt_2019-05-22_t004_video01.txt\",\n",
    "      \"gt\\cora_gt_2019-08-08_t004_video01.txt\",\n",
    "      \"gt\\cora5_gt.txt\",\n",
    "      \"gt\\cora_gt_2019-08-08_t014_video01.txt\",\n",
    "      \"gt\\marianne_gt_2016-03-22_t007_video01.txt\",\n",
    "      \"gt\\marianne_gt_2016-03-22_t008_video01.txt\",\n",
    "      \"gt\\marianne_gt_2016-03-22_t010_video01.txt\",\n",
    "      \"gt\\marianne_gt_2016-03-22_t018_video01.txt\",\n",
    "      \"gt\\marianne_gt_2016-03-22_t019_video01.txt\",\n",
    "      \"gt\\marianne_gt_2016-03-22_t024_video01.txt\",\n",
    "      \"gt\\marianne_gt_2016-03-22_t026_video01.txt\",\n",
    "      \"gt\\marianne_gt_2016-03-22_t041_video01.txt\",\n",
    "      \"gt\\marianne_gt_2016-03-22_t042_video01.txt\",\n",
    "      \"gt\\marianne_gt_2016-03-22_t043_video01.txt\",\n",
    "      \"gt\\marianne_gt_2016-03-22_t047_video01.txt\",\n",
    "      \"gt\\marianne_gt_2016-03-22_t048_video01.txt\",\n",
    "      \"gt\\muriel_gt_2016-03-21_t018_video01.txt\",\n",
    "      \"gt\\muriel_gt_2016-03-21_t026_video01.txt\",\n",
    "      \"gt\\muriel_gt_2016-03-21_t027_video01.txt\",\n",
    "      \"gt\\muriel_gt_2016-03-23_t030_video01.txt\"\n",
    "      ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Code</th>\n",
       "      <th>Age</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Name Code Age Weight\n",
       "0    1    2   3      4\n",
       "1    1    2   3      4"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test = pd.DataFrame(columns =['Name', 'Code', 'Age', 'Weight'])\n",
    "test = pd.concat([test, pd.DataFrame([[1,2,3,4]], columns=test.columns)], ignore_index=True)\n",
    "test = pd.concat([test, pd.DataFrame([[1,2,3,4]], columns=test.columns)], ignore_index=True)\n",
    "test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loluc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\claspy\\nearest_neighbour.py:252: NumbaTypeSafetyWarning: \u001b[1m\u001b[1m\u001b[1munsafe cast from uint64 to int64. Precision may be lost.\u001b[0m\u001b[0m\u001b[0m\n",
      "  start, end = pranges[idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1margin: (0.5333333333333333, 0.5, 0.5161290322580646)\n",
      "1\n",
      "f1margin: (0.7, 0.4375, 0.5384615384615384)\n",
      "2\n",
      "error IgnoreZone()\n",
      "f1margin: (0.3902439024390244, 0.9411764705882353, 0.5517241379310345)\n",
      "3\n",
      "error IgnoreZone()\n",
      "f1margin: (0.7142857142857143, 0.4, 0.5128205128205129)\n",
      "4\n",
      "error IgnoreZone()\n",
      "f1margin: (0.5, 0.6190476190476191, 0.5531914893617021)\n",
      "5\n",
      "error IgnoreZone()\n",
      "f1margin: (0.875, 0.25925925925925924, 0.39999999999999997)\n",
      "6\n",
      "error IgnoreZone()\n",
      "f1margin: (0.8888888888888888, 0.3076923076923077, 0.4571428571428572)\n",
      "7\n",
      "error IgnoreZone()\n",
      "f1margin: (0.6, 0.23076923076923078, 0.33333333333333337)\n",
      "8\n",
      "error IgnoreZone()\n",
      "f1margin: (0.9090909090909091, 0.2222222222222222, 0.3571428571428571)\n",
      "9\n",
      "error IgnoreZone()\n",
      "f1margin: (0.5217391304347826, 0.5454545454545454, 0.5333333333333332)\n",
      "10\n",
      "error IgnoreZone()\n",
      "f1margin: (0.5, 0.09523809523809523, 0.16)\n",
      "11\n",
      "error IgnoreZone()\n",
      "f1margin: (0.6923076923076923, 0.6923076923076923, 0.6923076923076923)\n",
      "12\n",
      "error IgnoreZone()\n",
      "f1margin: (0.25925925925925924, 0.7777777777777778, 0.3888888888888889)\n",
      "13\n",
      "error IgnoreZone()\n",
      "f1margin: (0.5098039215686274, 0.6666666666666666, 0.5777777777777778)\n",
      "14\n",
      "error IgnoreZone()\n",
      "f1margin: (1.0, 0.5294117647058824, 0.6923076923076924)\n",
      "15\n",
      "error IgnoreZone()\n",
      "f1margin: (0.7142857142857143, 0.29411764705882354, 0.4166666666666667)\n",
      "16\n",
      "f1margin: (0.9444444444444444, 0.4857142857142857, 0.6415094339622641)\n",
      "17\n",
      "f1margin: (0.896551724137931, 0.36619718309859156, 0.5200000000000001)\n",
      "18\n",
      "error IgnoreZone()\n",
      "f1margin: (0.9375, 0.189873417721519, 0.3157894736842105)\n",
      "19\n",
      "f1margin: (0.6666666666666666, 0.631578947368421, 0.6486486486486486)\n",
      "0\n",
      "f1margin: (0.5714285714285714, 0.375, 0.4528301886792453)\n",
      "1\n",
      "f1margin: (0.625, 0.3125, 0.4166666666666667)\n",
      "2\n",
      "error IgnoreZone()\n",
      "f1margin: (0.42105263157894735, 0.9411764705882353, 0.5818181818181818)\n",
      "3\n",
      "error IgnoreZone()\n",
      "f1margin: (0.7, 0.28, 0.4)\n",
      "4\n",
      "error IgnoreZone()\n",
      "f1margin: (0.75, 0.5714285714285714, 0.6486486486486486)\n",
      "5\n",
      "error IgnoreZone()\n",
      "f1margin: (0.875, 0.25925925925925924, 0.39999999999999997)\n",
      "6\n",
      "error IgnoreZone()\n",
      "f1margin: (1.0, 0.2692307692307692, 0.42424242424242425)\n",
      "7\n",
      "error IgnoreZone()\n",
      "f1margin: (0.8333333333333334, 0.19230769230769232, 0.3125)\n",
      "8\n",
      "error IgnoreZone()\n",
      "f1margin: (0.8571428571428571, 0.26666666666666666, 0.4067796610169491)\n",
      "9\n",
      "error IgnoreZone()\n",
      "f1margin: (0.5384615384615384, 0.3181818181818182, 0.39999999999999997)\n",
      "10\n",
      "error IgnoreZone()\n",
      "f1margin: (1.0, 0.19047619047619047, 0.32)\n",
      "11\n",
      "error IgnoreZone()\n",
      "f1margin: (0.5, 0.23076923076923078, 0.3157894736842105)\n",
      "12\n",
      "error IgnoreZone()\n",
      "f1margin: (0.1111111111111111, 0.1111111111111111, 0.1111111111111111)\n",
      "13\n",
      "error IgnoreZone()\n",
      "f1margin: (0.52, 0.3333333333333333, 0.40625000000000006)\n",
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loluc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\claspy\\segmentation.py:212: UserWarning: Time series must at least have 2*min_seg_size data points for segmentation. Try setting a smaller window size.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error IgnoreZone()\n",
      "f1margin: (1.0, 0.17647058823529413, 0.3)\n",
      "15\n",
      "error IgnoreZone()\n",
      "f1margin: (0.7142857142857143, 0.29411764705882354, 0.4166666666666667)\n",
      "16\n",
      "f1margin: (1.0, 0.11428571428571428, 0.20512820512820512)\n",
      "17\n",
      "f1margin: (0.8571428571428571, 0.08450704225352113, 0.15384615384615383)\n",
      "18\n",
      "error IgnoreZone()\n",
      "f1margin: (1.0, 0.13924050632911392, 0.2444444444444444)\n",
      "19\n",
      "f1margin: (0.7777777777777778, 0.18421052631578946, 0.2978723404255319)\n",
      "0\n",
      "f1margin: (0.3870967741935484, 0.375, 0.38095238095238093)\n",
      "1\n",
      "f1margin: (0.7, 0.4375, 0.5384615384615384)\n",
      "2\n",
      "error IgnoreZone()\n",
      "f1margin: (0.37209302325581395, 0.9411764705882353, 0.5333333333333333)\n",
      "3\n",
      "error IgnoreZone()\n",
      "f1margin: (0.8181818181818182, 0.36, 0.5)\n",
      "4\n",
      "error IgnoreZone()\n",
      "f1margin: (0.46153846153846156, 0.2857142857142857, 0.35294117647058826)\n",
      "5\n",
      "error IgnoreZone()\n",
      "f1margin: (0.9166666666666666, 0.4074074074074074, 0.5641025641025641)\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loluc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\claspy\\segmentation.py:212: UserWarning: Time series must at least have 2*min_seg_size data points for segmentation. Try setting a smaller window size.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error IgnoreZone()\n",
      "f1margin: (0.7777777777777778, 0.2692307692307692, 0.39999999999999997)\n",
      "7\n",
      "error IgnoreZone()\n",
      "f1margin: (0.7142857142857143, 0.19230769230769232, 0.30303030303030304)\n",
      "8\n",
      "error IgnoreZone()\n",
      "f1margin: (0.8333333333333334, 0.2222222222222222, 0.3508771929824561)\n",
      "9\n",
      "error IgnoreZone()\n",
      "f1margin: (0.45454545454545453, 0.45454545454545453, 0.45454545454545453)\n",
      "10\n",
      "error IgnoreZone()\n",
      "f1margin: (1.0, 0.19047619047619047, 0.32)\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loluc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\claspy\\segmentation.py:212: UserWarning: Time series must at least have 2*min_seg_size data points for segmentation. Try setting a smaller window size.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error IgnoreZone()\n",
      "f1margin: (0.5, 0.38461538461538464, 0.4347826086956522)\n",
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loluc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\claspy\\window_size.py:213: UserWarning: Could not find any autocorrelation peaks. Using window_size=10.\n",
      "  warnings.warn(f\"Could not find any autocorrelation peaks. Using window_size={lbound}.\")\n",
      "C:\\Users\\loluc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\stats\\_stats_py.py:9205: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  z = (s - expected) / np.sqrt(n1*n2*(n1+n2+1)/12.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error IgnoreZone()\n",
      "f1margin: (0.13157894736842105, 0.5555555555555556, 0.2127659574468085)\n",
      "13\n",
      "error IgnoreZone()\n",
      "f1margin: (0.4426229508196721, 0.6923076923076923, 0.5399999999999999)\n",
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loluc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\claspy\\segmentation.py:212: UserWarning: Time series must at least have 2*min_seg_size data points for segmentation. Try setting a smaller window size.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error IgnoreZone()\n",
      "f1margin: (1.0, 0.29411764705882354, 0.45454545454545453)\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loluc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\claspy\\segmentation.py:212: UserWarning: Time series must at least have 2*min_seg_size data points for segmentation. Try setting a smaller window size.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error IgnoreZone()\n",
      "f1margin: (0.7142857142857143, 0.29411764705882354, 0.4166666666666667)\n",
      "16\n",
      "f1margin: (0.9230769230769231, 0.34285714285714286, 0.5000000000000001)\n",
      "17\n",
      "f1margin: (0.9, 0.1267605633802817, 0.22222222222222224)\n",
      "18\n",
      "error IgnoreZone()\n",
      "f1margin: (0.8666666666666667, 0.16455696202531644, 0.2765957446808511)\n",
      "19\n",
      "f1margin: (0.6428571428571429, 0.47368421052631576, 0.5454545454545454)\n",
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "7 columns passed, passed data had 8 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\internals\\construction.py:969\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 969\u001b[0m     columns \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_or_indexify_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    971\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\internals\\construction.py:1017\u001b[0m, in \u001b[0;36m_validate_or_indexify_columns\u001b[1;34m(content, columns)\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_mi_list \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(content):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;66;03m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[1;32m-> 1017\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m   1018\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns passed, passed data had \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1019\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(content)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1020\u001b[0m     )\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_mi_list:\n\u001b[0;32m   1022\u001b[0m \n\u001b[0;32m   1023\u001b[0m     \u001b[38;5;66;03m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 7 columns passed, passed data had 8 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 62\u001b[0m\n\u001b[0;32m     60\u001b[0m     cp\u001b[38;5;241m=\u001b[39mdelnear(cp,\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m     61\u001b[0m     f1_list\u001b[38;5;241m=\u001b[39mEvaluateEvery(eachcp,gt,\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m---> 62\u001b[0m     outdf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([outdf, \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mf1_list\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     63\u001b[0m outdf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m:cleaned_array})\n\u001b[0;32m     64\u001b[0m outdf\u001b[38;5;241m.\u001b[39mto_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputFile/outputALLsingles.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:746\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    745\u001b[0m         columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[1;32m--> 746\u001b[0m     arrays, columns, index \u001b[38;5;241m=\u001b[39m \u001b[43mnested_data_to_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[0;32m    748\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[0;32m    749\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    752\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    754\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[0;32m    755\u001b[0m         arrays,\n\u001b[0;32m    756\u001b[0m         columns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    759\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    760\u001b[0m     )\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\internals\\construction.py:510\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[1;34m(data, columns, index, dtype)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    508\u001b[0m     columns \u001b[38;5;241m=\u001b[39m ensure_index(data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fields)\n\u001b[1;32m--> 510\u001b[0m arrays, columns \u001b[38;5;241m=\u001b[39m \u001b[43mto_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    511\u001b[0m columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\internals\\construction.py:875\u001b[0m, in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, dtype)\u001b[0m\n\u001b[0;32m    872\u001b[0m     data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[0;32m    873\u001b[0m     arr \u001b[38;5;241m=\u001b[39m _list_to_arrays(data)\n\u001b[1;32m--> 875\u001b[0m content, columns \u001b[38;5;241m=\u001b[39m \u001b[43m_finalize_columns_and_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content, columns\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\internals\\construction.py:972\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    969\u001b[0m     columns \u001b[38;5;241m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[0;32m    970\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    971\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[1;32m--> 972\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(contents) \u001b[38;5;129;01mand\u001b[39;00m contents[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[0;32m    975\u001b[0m     contents \u001b[38;5;241m=\u001b[39m _convert_object_array(contents, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: 7 columns passed, passed data had 8 columns"
     ]
    }
   ],
   "source": [
    "# colonna dei nomi dei file\n",
    "cleaned_array = [s[3:-7] for s in timeseries]\n",
    "\n",
    "# excel file per output f1score con feature classiche\n",
    "outdf = pd.DataFrame({\"name\":cleaned_array})\n",
    "\n",
    "\n",
    "#suss, euclidean, 4\n",
    "outeval=[]\n",
    "for i in range(len(timeseries)):\n",
    "    print(i)\n",
    "    df=ReadAndPreProcess(timeseries[i])\n",
    "    gt=LoadingGroundTruth(df,groundtruth[i])\n",
    "    cp,eachcp,clasp=GetClaspOld(df,gt,0,window_size=\"suss\", distance=\"euclidean_distance\", excl_radius=4)\n",
    "    #PlotResult(df,gt,cp, timeseries[i], 100)\n",
    "    cp=IgnoreZone(i,cp)\n",
    "    cp=delnear(cp,100)\n",
    "    precision,recall,f1=Evaluate(\"CLASP\",groundtruth[i],gt,timeseries[i],cp,df,100,\"suss euclidean 4\",timeseries[i])\n",
    "    outeval.append(f1)\n",
    "outdf[\"suss_euclidean_4\"] = outeval\n",
    "\n",
    "#fft, euclidean, 4\n",
    "outeval=[]\n",
    "for i in range(len(timeseries)):\n",
    "    print(i)\n",
    "    df=ReadAndPreProcess(timeseries[i])\n",
    "    gt=LoadingGroundTruth(df,groundtruth[i])\n",
    "    cp,eachcp,clasp=GetClaspOld(df,gt,0,window_size=\"fft\", distance=\"euclidean_distance\", excl_radius=4)\n",
    "    #PlotResult(df,gt,cp, timeseries[i], 100)\n",
    "    cp=IgnoreZone(i,cp)\n",
    "    cp=delnear(cp,100)\n",
    "    precision,recall,f1=Evaluate(\"CLASP\",groundtruth[i],gt,timeseries[i],cp,df,100,\"fft euclidean 4\",timeseries[i])\n",
    "    outeval.append(f1)\n",
    "outdf[\"fft_euclidean_4\"] = outeval\n",
    "\n",
    "#acf, euclidean, 4\n",
    "outeval=[]\n",
    "for i in range(len(timeseries)):\n",
    "    print(i)\n",
    "    df=ReadAndPreProcess(timeseries[i])\n",
    "    gt=LoadingGroundTruth(df,groundtruth[i])\n",
    "    cp,eachcp,clasp=GetClaspOld(df,gt,0,window_size=\"acf\", distance=\"euclidean_distance\", excl_radius=4)\n",
    "    #PlotResult(df,gt,cp, timeseries[i], 100)\n",
    "    cp=IgnoreZone(i,cp)\n",
    "    cp=delnear(cp,100)\n",
    "    precision,recall,f1=Evaluate(\"CLASP\",groundtruth[i],gt,timeseries[i],cp,df,100,\"acf euclidean 4\",timeseries[i])\n",
    "    outeval.append(f1)\n",
    "outdf[\"acf_euclidean_4\"] = outeval\n",
    "\n",
    "\n",
    "\n",
    "#f1scores\n",
    "outdf2 = pd.DataFrame(columns = features_name)#['kineticglobal', 'density','leftwirstke', 'rightwristke', 'leftankleke', 'rightankleke', 'headke'])\n",
    "\n",
    "#ratio prediction\n",
    "outdf3 = pd.DataFrame(columns = features_name)\n",
    "\n",
    "#suss, euclidean, 4\n",
    "outeval=[]\n",
    "for i in range(len(timeseries)):\n",
    "    print(i)\n",
    "    df=ReadAndPreProcess(timeseries[i])\n",
    "    gt=LoadingGroundTruth(df,groundtruth[i])\n",
    "    cp,eachcp,clasp=GetClasp(df,gt,0,window_size=\"suss\", distance=\"euclidean_distance\", excl_radius=4)\n",
    "    for idx,j in enumerate(eachcp):\n",
    "        eachcp[idx] = IgnoreZone(i,j)\n",
    "    f1_list,ratio_list=EvaluateEvery(eachcp,gt,100)\n",
    "    outdf2 = pd.concat([outdf2, pd.DataFrame([f1_list], columns=outdf2.columns)], ignore_index=True)\n",
    "    outdf3 = pd.concat([outdf3, pd.DataFrame([ratio_list], columns=outdf3.columns)], ignore_index=True)\n",
    "outdf2[\"name\"]=cleaned_array\n",
    "outdf3[\"name\"]=cleaned_array\n",
    "\n",
    "outdf.to_excel(\"outputFile/outputALL.xlsx\")\n",
    "outdf2.to_excel(\"outputFile/outputALLsingles.xlsx\")\n",
    "outdf3.to_excel(\"outputFile/outputALLsinglesRATIO.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
