{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tikyn\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\aeon\\base\\__init__.py:24: FutureWarning: The aeon package will soon be releasing v1.0.0 with the removal of legacy modules and interfaces such as BaseTransformer and BaseForecaster. This will contain breaking changes. See aeon-toolkit.org for more information. Set aeon.AEON_DEPRECATION_WARNING or the AEON_DEPRECATION_WARNING environmental variable to 'False' to disable this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>The whole model works in this order</b>\n",
    "<ol>\n",
    "    <li>clasp model - in: features ts [98][n] - out: prediction [98][m]</li>\n",
    "    <li>split saliency - in: prediction[98][m] - out: pred_split [6][k][m]</li>\n",
    "    <li>combinesinglesaliency - in: pred_split[6][k][m] - out: salience_preds [6][m]</li>\n",
    "    <li>union salience_preds - in: salience_preds [6][m] - out: union_pred [m]</li>\n",
    "    <li>ignorezone - in: union_pred [m] - out: ignored_pred [m]</li>\n",
    "    <li>delnear - in: ignored_pred [m] - out: del_pred [m]</li>\n",
    "    <li>DTW - in: del_pred [m] - out: dtw_pred [m]</li>\n",
    "    <li>scoring - in: dtw_pred [m] - out: f1score</li>\n",
    "</ol>\n",
    "\n",
    "This project is divided into three part, because each part takes a lot of days for computing the result:\n",
    "<ol>\n",
    "    <li>Clasp Model: (1) -> create all prediction from the clasp model</li>\n",
    "    <li>Filtering: (2)(3)(4)(5)(6)(7) -> filters all prediction to remove false positives</li>\n",
    "    <li>Scoring: (8) -> given the filtered prediction, gives an evaluation</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Clasp Model (1)</b>\n",
    "We use ParameterGrid() to compute all the combination given the param_grid and we obtained <b>19</b> different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"window_size\": ['suss'],\n",
    "    \"distance\": ['euclidean_distance'],\n",
    "    \"score\":['roc_auc','f1'],\n",
    "    \"early_stopping\": [True,False],\n",
    "    \"k_neighbours\":[1,3,5,7,9],\n",
    "    \"n_jobs\":[4]\n",
    "}\n",
    "\n",
    "\n",
    "# 21*98 = 2058 timeseries\n",
    "for p_idx,params in enumerate(ParameterGrid(param_grid)):\n",
    "    params[\"excl_radius\"]=params[\"k_neighbours\"]+2\n",
    "    cpsl=[]\n",
    "    for i in range(len(TIMESERIES)):\n",
    "        df=ReadAndPreProcess(TIMESERIES[i])\n",
    "        gt=LoadingGroundTruth(df,GROUNDTRUTH[i])\n",
    "        #cp_all,cps,clasp=GetClasp2(df,gt,0,list(range(len(features_name))), window_size=\"suss\",distance=\"euclidean_distance\",n_jobs=6)\n",
    "        cp_all,cps,clasp=GetClasp2(df,gt,list(range(len(features_name))),p_idx,i, **params)\n",
    "        cpsl.append(cps)\n",
    "\n",
    "\n",
    "    with open(\"../cpsl_param_\"+str(p_idx)+\".pkl\", \"wb\") as f:\n",
    "        pickle.dump(cpsl, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Filtering (2)(3)(4)(5)(6)(7)</b>\n",
    "The gridsearch isn't finished yet. Each step has its known set of parameters that needs to be found to have the optimal model. So in the filtering phase we gridsearch all values and generate all possible filtered prediction from each different. \n",
    "\n",
    "The computational costs is made by for loops:\n",
    "<p>for each models = 19</p>\n",
    "<p style=\"text-indent: 15px;\">for each params = 243 </p>\n",
    "<p style=\"text-indent: 30px;\">for each videos = 21 </p>\n",
    "<p style=\"text-indent: 45px;\">for each features = 98</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx:0 {'distance': 'euclidean_distance', 'early_stopping': True, 'k_neighbours': 1, 'n_jobs': 4, 'score': 'roc_auc', 'window_size': 'suss'}\n",
      "idx:1 {'distance': 'euclidean_distance', 'early_stopping': True, 'k_neighbours': 1, 'n_jobs': 4, 'score': 'f1', 'window_size': 'suss'}\n",
      "idx:2 {'distance': 'euclidean_distance', 'early_stopping': True, 'k_neighbours': 3, 'n_jobs': 4, 'score': 'roc_auc', 'window_size': 'suss'}\n",
      "idx:3 {'distance': 'euclidean_distance', 'early_stopping': True, 'k_neighbours': 3, 'n_jobs': 4, 'score': 'f1', 'window_size': 'suss'}\n",
      "idx:4 {'distance': 'euclidean_distance', 'early_stopping': True, 'k_neighbours': 5, 'n_jobs': 4, 'score': 'roc_auc', 'window_size': 'suss'}\n",
      "idx:5 {'distance': 'euclidean_distance', 'early_stopping': True, 'k_neighbours': 5, 'n_jobs': 4, 'score': 'f1', 'window_size': 'suss'}\n",
      "idx:6 {'distance': 'euclidean_distance', 'early_stopping': True, 'k_neighbours': 7, 'n_jobs': 4, 'score': 'roc_auc', 'window_size': 'suss'}\n",
      "idx:7 {'distance': 'euclidean_distance', 'early_stopping': True, 'k_neighbours': 7, 'n_jobs': 4, 'score': 'f1', 'window_size': 'suss'}\n",
      "idx:8 {'distance': 'euclidean_distance', 'early_stopping': True, 'k_neighbours': 9, 'n_jobs': 4, 'score': 'roc_auc', 'window_size': 'suss'}\n",
      "idx:9 {'distance': 'euclidean_distance', 'early_stopping': True, 'k_neighbours': 9, 'n_jobs': 4, 'score': 'f1', 'window_size': 'suss'}\n",
      "idx:10 {'distance': 'euclidean_distance', 'early_stopping': False, 'k_neighbours': 1, 'n_jobs': 4, 'score': 'roc_auc', 'window_size': 'suss'}\n",
      "idx:11 {'distance': 'euclidean_distance', 'early_stopping': False, 'k_neighbours': 1, 'n_jobs': 4, 'score': 'f1', 'window_size': 'suss'}\n",
      "idx:12 {'distance': 'euclidean_distance', 'early_stopping': False, 'k_neighbours': 3, 'n_jobs': 4, 'score': 'roc_auc', 'window_size': 'suss'}\n",
      "idx:13 {'distance': 'euclidean_distance', 'early_stopping': False, 'k_neighbours': 3, 'n_jobs': 4, 'score': 'f1', 'window_size': 'suss'}\n",
      "idx:14 {'distance': 'euclidean_distance', 'early_stopping': False, 'k_neighbours': 5, 'n_jobs': 4, 'score': 'roc_auc', 'window_size': 'suss'}\n",
      "idx:15 {'distance': 'euclidean_distance', 'early_stopping': False, 'k_neighbours': 5, 'n_jobs': 4, 'score': 'f1', 'window_size': 'suss'}\n",
      "idx:16 {'distance': 'euclidean_distance', 'early_stopping': False, 'k_neighbours': 7, 'n_jobs': 4, 'score': 'roc_auc', 'window_size': 'suss'}\n",
      "idx:17 {'distance': 'euclidean_distance', 'early_stopping': False, 'k_neighbours': 7, 'n_jobs': 4, 'score': 'f1', 'window_size': 'suss'}\n",
      "idx:18 {'distance': 'euclidean_distance', 'early_stopping': False, 'k_neighbours': 9, 'n_jobs': 4, 'score': 'roc_auc', 'window_size': 'suss'}\n",
      "idx:19 {'distance': 'euclidean_distance', 'early_stopping': False, 'k_neighbours': 9, 'n_jobs': 4, 'score': 'f1', 'window_size': 'suss'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"window_size\": ['suss'],\n",
    "    \"distance\": ['euclidean_distance'],\n",
    "    \"score\":['roc_auc','f1'],\n",
    "    \"early_stopping\": [True,False],\n",
    "    \"k_neighbours\":[1,3,5,7,9],\n",
    "    \"n_jobs\":[4]\n",
    "}\n",
    "for p_idx,params in enumerate(ParameterGrid(param_grid)):\n",
    "    print(f'idx:{p_idx} {params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../dfl.pkl\", \"rb\") as f:\n",
    "    dfl = pickle.load(f)\n",
    "\n",
    "with open(\"../gtl.pkl\", \"rb\") as f:\n",
    "    gtl = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. model setting: already computed with given upper hyperparameters\n",
    "modelpred=[]\n",
    "for i in range(0,20):\n",
    "    with open(\"../cpsl_param_\"+str(i)+\".pkl\", \"rb\") as f:\n",
    "        modelpred.append(pickle.load(f))\n",
    "\n",
    "#20 model\n",
    "#21 video\n",
    "#98 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. splitting\n",
    "def SplitSaliency(pred):\n",
    "    # 2. split features in 6 saliency groups\n",
    "    # vel,acc,jerk,specific,generic\n",
    "    # specific: other type of feature specific for that saliency\n",
    "    # generic: other type of feature that describe the whole body movement\n",
    "    ## generic features: 0,3\n",
    "    ariel_el=[26,27,28,29,30,31,32,33,34,35,36,37,2,8,14,0,3]\n",
    "    ariel = UnionCPS(*pred[ariel_el])\n",
    "   \n",
    "    strn_el=[38,39,40,41,42,43,44,45,46,47,48,49,1,9,0,3]\n",
    "    strn = UnionCPS(*pred[strn_el])\n",
    "\n",
    "    rhel_el=[50,51,52,53,54,55,56,57,58,59,60,61,7,11,16,17,18,21,0,3]\n",
    "    rhel = UnionCPS(*pred[rhel_el])\n",
    "\n",
    "    lhel_el=[62,63,64,65,66,67,68,69,70,71,72,73,6,10,16,17,19,20,0,3]\n",
    "    lhel = UnionCPS(*pred[lhel_el])\n",
    "    \n",
    "    rplm_el=[74,75,76,77,78,79,80,81,82,83,84,85,5,13,15,23,25,0,3]\n",
    "    rplm = UnionCPS(*pred[rplm_el])\n",
    "\n",
    "    lplm_el=[86,87,88,89,90,91,92,93,94,95,96,97,4,12,15,22,24,0,3]\n",
    "    lplm = UnionCPS(*pred[lplm_el])\n",
    "\n",
    "    return [ariel,strn,rhel,lhel,rplm,lplm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.\n",
    "def CombineSingleSaliency(saliencies, maj_margin, maj_thre):\n",
    "    res=[]\n",
    "    for sal in saliencies:\n",
    "        res.append(MajorityVoteCP(sal, maj_margin, maj_thre))\n",
    "    return res\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#98 per un solo video\n",
    "\n",
    "# 1. model setting - in: 98 timeseries - out: 98 prediction\n",
    "# 2. splittare in 6 salienze - in: 98 prediction - out: 98 into 6 list[salienza][feature][elemento singolo] (could be repetition)\n",
    "# 3xyz. majvote(threshold,margin) - in: 6 list[][][] - out: 6 list[salienza][elemento singolo]\n",
    "# 3tog. majvote(threshold,margin) - in: 6 list[][][] - out: 6 list[salienza][elemento singolo]\n",
    "# 4. unione - in: 6 list[][] - out: list[]\n",
    "# 5. ignorezone(margin)\n",
    "# 6. delnear(margin)\n",
    "# 7. dtw(threshold)\n",
    "def PostFilterTogether(model_id,video_id,param_id,param_len,density,pred,gt, maj_margin, maj_thre, zone_margin, del_margin, dtw_threshold):\n",
    "    \"\"\"\n",
    "        pred: 98 predictions of a single video\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"model:{model_id}/20 - video:{video_id}/21 - param:{param_id}/{param_len} - Start                                               \", end='\\r')\n",
    "\n",
    "    #2.\n",
    "    saliencies_raw = SplitSaliency(pred)\n",
    "    print(f\"model:{model_id}/20 - video:{video_id}/21 - param:{param_id}/{param_len} - Split Saliency completed                            \", end='\\r')\n",
    "    #3.\n",
    "    saliencies = CombineSingleSaliency(saliencies_raw,maj_margin,maj_thre)\n",
    "    print(f\"model:{model_id}/20 - video:{video_id}/21 - param:{param_id}/{param_len} - Combine Saliency completed                          \", end='\\r')\n",
    "    #4.\n",
    "    pred_united = UnionCPS(saliencies)\n",
    "    print(f\"model:{model_id}/20 - video:{video_id}/21 - param:{param_id}/{param_len} - Union completed                                     \", end='\\r')\n",
    "    #5.\n",
    "    pred_ignored = IgnoreZone(video_id,pred_united,gt,zone_margin)\n",
    "    print(f\"model:{model_id}/20 - video:{video_id}/21 - param:{param_id}/{param_len} - Ignore Zone completed                               \", end='\\r')\n",
    "    #6.\n",
    "    pred_del = delnear(pred_ignored,del_margin)\n",
    "    print(f\"model:{model_id}/20 - video:{video_id}/21 - param:{param_id}/{param_len} - delnear completed                                   \", end='\\r')\n",
    "    #7.\n",
    "    pred_final=FPremoverDTW(density,pred_del,dtw_threshold)\n",
    "    print(f\"model:{model_id}/20 - param:{param_id}/{param_len} - video:{video_id}/21 - DTW completed                                       \", end='\\r')\n",
    "    # pred_modelid_videoid_majmargin_majthree_zonemargin_delmargin_dtwthreshold\n",
    "    return pred_final\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "x=[[2,4,6],[3,5,7],[10,20,30]]\n",
    "print(UnionCPS(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:19/20 - video:20/21 - param:242/243 - DTW completed                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nversione 1\\nfisso param_grid\\ncalcolo f1 score per only training fold\\nprendo il migliore\\ncalcolo per ogni singolo video nel validation\\n\\nfor model in models:\\n    for param in paramgrid:\\n        for fold in folds:\\n            for ts in fold.train:\\n                f1s_1 = compute single f1score \\n                calcolo f1score per singolo ts\\n            f1s_mean = compute mean f1score mean(f1s_1,f1s_1,...)\\n            per un intero train_set ritorno lo il f1score medio\\n        f1s_mean_mean = compute mean of f1s_mean(f1s_mean,f1s_mean,...)\\n        per ogni train_set ritorno la media = come performa questo param across all folds\\n    check best f1s_mean_mean\\nper ogni param diverso, controllo quello che mi massimizza\\nO(n^3)\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#leave one video out\n",
    "\n",
    "param_grid = {\n",
    "    \"maj_margin\": [80,100,120],\n",
    "    \"maj_thre\": [1,2,3],\n",
    "    \"zone_margin\":[80,100,120],\n",
    "    \"del_margin\": [80,100,120],\n",
    "    \"dtw_threshold\":[80,100,120]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# 21*98 = 2058 timeseries\n",
    "model_res=[]\n",
    "for model_id,model in enumerate(modelpred): #20 models predictions\n",
    "    param_value=[]\n",
    "    for p_idx,params in enumerate(ParameterGrid(param_grid)):\n",
    "        video=[]\n",
    "        for i in range(len(TIMESERIES)): #21 videos\n",
    "            df = dfl[i]\n",
    "            gt = gtl[i]\n",
    "            res=PostFilterTogether(model_id,i,p_idx,len(ParameterGrid(param_grid)),df.iloc[:,3],np.array(model[i],dtype=\"object\"),gt,params[\"maj_margin\"],params[\"maj_thre\"],params[\"zone_margin\"],params[\"del_margin\"],params[\"dtw_threshold\"])\n",
    "            video.append(res)\n",
    "            \"\"\"\n",
    "            i folds servono solo durante lo scoring\n",
    "            # single fold\n",
    "            train_set = [j for j in range(len(TIMESERIES)) if j != i]\n",
    "            test_set = i\n",
    "            for ts in train_set:\n",
    "                PostFilterTogether()\n",
    "            \"\"\"\n",
    "        param_value.append(video)\n",
    "    model_res.append(param_value)\n",
    "\n",
    "with open(\"../collection_models_prediction_filtered.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model_res, f)\n",
    "    \n",
    "    #fuori dal for deve calcolare la media\n",
    "    \n",
    "\"\"\"\n",
    "versione 1\n",
    "fisso param_grid\n",
    "calcolo f1 score per only training fold\n",
    "prendo il migliore\n",
    "calcolo per ogni singolo video nel validation\n",
    "\n",
    "for model in models:\n",
    "    for param in paramgrid:\n",
    "        for fold in folds:\n",
    "            for ts in fold.train:\n",
    "                f1s_1 = compute single f1score \n",
    "                calcolo f1score per singolo ts\n",
    "            f1s_mean = compute mean f1score mean(f1s_1,f1s_1,...)\n",
    "            per un intero train_set ritorno lo il f1score medio\n",
    "        f1s_mean_mean = compute mean of f1s_mean(f1s_mean,f1s_mean,...)\n",
    "        per ogni train_set ritorno la media = come performa questo param across all folds\n",
    "    check best f1s_mean_mean\n",
    "per ogni param diverso, controllo quello che mi massimizza\n",
    "O(n^3)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
