{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>The whole model works in this order</b>\n",
    "<ol>\n",
    "    <li>clasp model - in: features ts [98][n] - out: prediction [98][m]</li>\n",
    "    <li>split saliency - in: prediction[98][m] - out: pred_split [6][k][m]</li>\n",
    "    <li>combinesinglesaliency - in: pred_split[6][k][m] - out: salience_preds [6][m]</li>\n",
    "    <li>union salience_preds - in: salience_preds [6][m] - out: union_pred [m]</li>\n",
    "    <li>ignorezone - in: union_pred [m] - out: ignored_pred [m]</li>\n",
    "    <li>delnear - in: ignored_pred [m] - out: del_pred [m]</li>\n",
    "    <li>DTW - in: del_pred [m] - out: dtw_pred [m]</li>\n",
    "    <li>scoring - in: dtw_pred [m] - out: f1score</li>\n",
    "</ol>\n",
    "\n",
    "This project is divided into three part, because each part takes a lot of days for computing the result:\n",
    "<ol>\n",
    "    <li>Clasp Model: (1) -> create all prediction from the clasp model</li>\n",
    "    <li>Filtering: (2)(3)(4)(5)(6)(7) -> filters all prediction to remove false positives</li>\n",
    "    <li>Scoring: (8) -> given the filtered prediction, gives an evaluation</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Clasp Model (1)</b>\n",
    "We use ParameterGrid() to compute all the combination given the param_grid and we obtained <b>19</b> different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"window_size\": ['suss'],\n",
    "    \"distance\": ['euclidean_distance'],\n",
    "    \"score\":['roc_auc','f1'],\n",
    "    \"early_stopping\": [True,False],\n",
    "    \"k_neighbours\":[1,3,5,7,9],\n",
    "    \"n_jobs\":[4]\n",
    "}\n",
    "\n",
    "\n",
    "# 21*98 = 2058 timeseries\n",
    "for p_idx,params in enumerate(ParameterGrid(param_grid)):\n",
    "    params[\"excl_radius\"]=params[\"k_neighbours\"]+2\n",
    "    cpsl=[]\n",
    "    for i in range(len(TIMESERIES)):\n",
    "        df=ReadAndPreProcess(TIMESERIES[i])\n",
    "        gt=LoadingGroundTruth(df,GROUNDTRUTH[i])\n",
    "        #cp_all,cps,clasp=GetClasp2(df,gt,0,list(range(len(features_name))), window_size=\"suss\",distance=\"euclidean_distance\",n_jobs=6)\n",
    "        cp_all,cps,clasp=GetClasp2(df,gt,list(range(len(features_name))),p_idx,i, **params)\n",
    "        cpsl.append(cps)\n",
    "\n",
    "\n",
    "    with open(\"../cpsl_param_\"+str(p_idx)+\".pkl\", \"wb\") as f:\n",
    "        pickle.dump(cpsl, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Filtering (2)(3)(4)(5)(6)(7)</b>\n",
    "The gridsearch isn't finished yet. Each step has its known set of parameters that needs to be found to have the optimal model. So in the filtering phase we gridsearch all values and generate all possible filtered prediction from each different. \n",
    "\n",
    "The computational costs is made by for loops:\n",
    "<p>for each models = 19</p>\n",
    "<p style=\"text-indent: 15px;\">for each params = 243 </p>\n",
    "<p style=\"text-indent: 30px;\">for each videos = 21 </p>\n",
    "<p style=\"text-indent: 45px;\">for each features = 98</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../dfl.pkl\", \"rb\") as f:\n",
    "    dfl = pickle.load(f)\n",
    "\n",
    "with open(\"../gtl.pkl\", \"rb\") as f:\n",
    "    gtl = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. model setting: already computed with given upper hyperparameters\n",
    "modelpred=[]\n",
    "for i in range(0,20):\n",
    "    with open(\"../cpsl_param_\"+str(i)+\".pkl\", \"rb\") as f:\n",
    "        modelpred.append(pickle.load(f))\n",
    "\n",
    "#20 model\n",
    "#21 video\n",
    "#98 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx:0 {'distance': 'euclidean_distance', 'early_stopping': True, 'k_neighbours': 1, 'n_jobs': 4, 'score': 'roc_auc', 'window_size': 'suss'}\n",
      "idx:1 {'distance': 'euclidean_distance', 'early_stopping': True, 'k_neighbours': 1, 'n_jobs': 4, 'score': 'f1', 'window_size': 'suss'}\n",
      "idx:2 {'distance': 'euclidean_distance', 'early_stopping': True, 'k_neighbours': 3, 'n_jobs': 4, 'score': 'roc_auc', 'window_size': 'suss'}\n",
      "idx:3 {'distance': 'euclidean_distance', 'early_stopping': True, 'k_neighbours': 3, 'n_jobs': 4, 'score': 'f1', 'window_size': 'suss'}\n",
      "idx:4 {'distance': 'euclidean_distance', 'early_stopping': True, 'k_neighbours': 5, 'n_jobs': 4, 'score': 'roc_auc', 'window_size': 'suss'}\n",
      "idx:5 {'distance': 'euclidean_distance', 'early_stopping': True, 'k_neighbours': 5, 'n_jobs': 4, 'score': 'f1', 'window_size': 'suss'}\n",
      "idx:6 {'distance': 'euclidean_distance', 'early_stopping': True, 'k_neighbours': 7, 'n_jobs': 4, 'score': 'roc_auc', 'window_size': 'suss'}\n",
      "idx:7 {'distance': 'euclidean_distance', 'early_stopping': True, 'k_neighbours': 7, 'n_jobs': 4, 'score': 'f1', 'window_size': 'suss'}\n",
      "idx:8 {'distance': 'euclidean_distance', 'early_stopping': True, 'k_neighbours': 9, 'n_jobs': 4, 'score': 'roc_auc', 'window_size': 'suss'}\n",
      "idx:9 {'distance': 'euclidean_distance', 'early_stopping': True, 'k_neighbours': 9, 'n_jobs': 4, 'score': 'f1', 'window_size': 'suss'}\n",
      "idx:10 {'distance': 'euclidean_distance', 'early_stopping': False, 'k_neighbours': 1, 'n_jobs': 4, 'score': 'roc_auc', 'window_size': 'suss'}\n",
      "idx:11 {'distance': 'euclidean_distance', 'early_stopping': False, 'k_neighbours': 1, 'n_jobs': 4, 'score': 'f1', 'window_size': 'suss'}\n",
      "idx:12 {'distance': 'euclidean_distance', 'early_stopping': False, 'k_neighbours': 3, 'n_jobs': 4, 'score': 'roc_auc', 'window_size': 'suss'}\n",
      "idx:13 {'distance': 'euclidean_distance', 'early_stopping': False, 'k_neighbours': 3, 'n_jobs': 4, 'score': 'f1', 'window_size': 'suss'}\n",
      "idx:14 {'distance': 'euclidean_distance', 'early_stopping': False, 'k_neighbours': 5, 'n_jobs': 4, 'score': 'roc_auc', 'window_size': 'suss'}\n",
      "idx:15 {'distance': 'euclidean_distance', 'early_stopping': False, 'k_neighbours': 5, 'n_jobs': 4, 'score': 'f1', 'window_size': 'suss'}\n",
      "idx:16 {'distance': 'euclidean_distance', 'early_stopping': False, 'k_neighbours': 7, 'n_jobs': 4, 'score': 'roc_auc', 'window_size': 'suss'}\n",
      "idx:17 {'distance': 'euclidean_distance', 'early_stopping': False, 'k_neighbours': 7, 'n_jobs': 4, 'score': 'f1', 'window_size': 'suss'}\n",
      "idx:18 {'distance': 'euclidean_distance', 'early_stopping': False, 'k_neighbours': 9, 'n_jobs': 4, 'score': 'roc_auc', 'window_size': 'suss'}\n",
      "idx:19 {'distance': 'euclidean_distance', 'early_stopping': False, 'k_neighbours': 9, 'n_jobs': 4, 'score': 'f1', 'window_size': 'suss'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"window_size\": ['suss'],\n",
    "    \"distance\": ['euclidean_distance'],\n",
    "    \"score\":['roc_auc','f1'],\n",
    "    \"early_stopping\": [True,False],\n",
    "    \"k_neighbours\":[1,3,5,7,9],\n",
    "    \"n_jobs\":[4]\n",
    "}\n",
    "for p_idx,params in enumerate(ParameterGrid(param_grid)):\n",
    "    print(f'idx:{p_idx} {params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. splitting\n",
    "def SplitSaliency(pred):\n",
    "    # 2. split features in 6 saliency groups\n",
    "    # vel,acc,jerk,specific,generic\n",
    "    # specific: other type of feature specific for that saliency\n",
    "    # generic: other type of feature that describe the whole body movement\n",
    "    ## generic features: 0,3\n",
    "    ariel_el=[26,27,28,29,30,31,32,33,34,35,36,37,2,8,14,0,3]\n",
    "    ariel = UnionCPS(*pred[ariel_el])\n",
    "   \n",
    "    strn_el=[38,39,40,41,42,43,44,45,46,47,48,49,1,9,0,3]\n",
    "    strn = UnionCPS(*pred[strn_el])\n",
    "\n",
    "    rhel_el=[50,51,52,53,54,55,56,57,58,59,60,61,7,11,16,17,18,21,0,3]\n",
    "    rhel = UnionCPS(*pred[rhel_el])\n",
    "\n",
    "    lhel_el=[62,63,64,65,66,67,68,69,70,71,72,73,6,10,16,17,19,20,0,3]\n",
    "    lhel = UnionCPS(*pred[lhel_el])\n",
    "    \n",
    "    rplm_el=[74,75,76,77,78,79,80,81,82,83,84,85,5,13,15,23,25,0,3]\n",
    "    rplm = UnionCPS(*pred[rplm_el])\n",
    "\n",
    "    lplm_el=[86,87,88,89,90,91,92,93,94,95,96,97,4,12,15,22,24,0,3]\n",
    "    lplm = UnionCPS(*pred[lplm_el])\n",
    "\n",
    "    return [ariel,strn,rhel,lhel,rplm,lplm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.\n",
    "def CombineSingleSaliency(saliencies, maj_margin, maj_thre):\n",
    "    res=[]\n",
    "    for sal in saliencies:\n",
    "        res.append(MajorityVoteCP(sal, maj_margin, maj_thre))\n",
    "    return res\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#98 per un solo video\n",
    "\n",
    "# 1. model setting - in: 98 timeseries - out: 98 prediction\n",
    "# 2. splittare in 6 salienze - in: 98 prediction - out: 98 into 6 list[salienza][feature][elemento singolo] (could be repetition)\n",
    "# 3xyz. majvote(threshold,margin) - in: 6 list[][][] - out: 6 list[salienza][elemento singolo]\n",
    "# 3tog. majvote(threshold,margin) - in: 6 list[][][] - out: 6 list[salienza][elemento singolo]\n",
    "# 4. unione - in: 6 list[][] - out: list[]\n",
    "# 5. ignorezone(margin)\n",
    "# 6. delnear(margin)\n",
    "# 7. dtw(threshold)\n",
    "def PostFilterTogether(model_id,video_id,param_id,param_len,density,pred,gt, maj_margin, maj_thre, zone_margin, del_margin, dtw_threshold):\n",
    "    \"\"\"\n",
    "        pred: 98 predictions of a single video\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"model:{model_id}/20 - video:{video_id}/21 - param:{param_id}/{param_len} - Start                                               \", end='\\r')\n",
    "\n",
    "    #2.\n",
    "    saliencies_raw = SplitSaliency(pred)\n",
    "    print(f\"model:{model_id}/20 - video:{video_id}/21 - param:{param_id}/{param_len} - Split Saliency completed                            \", end='\\r')\n",
    "    #3.\n",
    "    saliencies = CombineSingleSaliency(saliencies_raw,maj_margin,maj_thre)\n",
    "    print(f\"model:{model_id}/20 - video:{video_id}/21 - param:{param_id}/{param_len} - Combine Saliency completed                          \", end='\\r')\n",
    "    #4.\n",
    "    pred_united = UnionCPS(*saliencies)\n",
    "    print(f\"model:{model_id}/20 - video:{video_id}/21 - param:{param_id}/{param_len} - Union completed                                     \", end='\\r')\n",
    "    #5.\n",
    "    pred_ignored = IgnoreZone(video_id,pred_united,gt,zone_margin)\n",
    "    print(f\"model:{model_id}/20 - video:{video_id}/21 - param:{param_id}/{param_len} - Ignore Zone completed                               \", end='\\r')\n",
    "    #6.\n",
    "    pred_del = delnear(pred_ignored,del_margin)\n",
    "    print(f\"model:{model_id}/20 - video:{video_id}/21 - param:{param_id}/{param_len} - delnear completed                                   \", end='\\r')\n",
    "    #7.\n",
    "    pred_final=FPremoverDTW(density,pred_del,dtw_threshold)\n",
    "    print(f\"model:{model_id}/20 - param:{param_id}/{param_len} - video:{video_id}/21 - DTW completed                                       \", end='\\r')\n",
    "    # pred_modelid_videoid_majmargin_majthree_zonemargin_delmargin_dtwthreshold\n",
    "    return pred_final\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:19/20 - param:242/243 - video:20/21 - DTW completed                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nversione 1\\nfisso param_grid\\ncalcolo f1 score per only training fold\\nprendo il migliore\\ncalcolo per ogni singolo video nel validation\\n\\nfor model in models:\\n    for param in paramgrid:\\n        for fold in folds:\\n            for ts in fold.train:\\n                f1s_1 = compute single f1score \\n                calcolo f1score per singolo ts\\n            f1s_mean = compute mean f1score mean(f1s_1,f1s_1,...)\\n            per un intero train_set ritorno lo il f1score medio\\n        f1s_mean_mean = compute mean of f1s_mean(f1s_mean,f1s_mean,...)\\n        per ogni train_set ritorno la media = come performa questo param across all folds\\n    check best f1s_mean_mean\\nper ogni param diverso, controllo quello che mi massimizza\\nO(n^3)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#leave one video out\n",
    "\n",
    "param_grid = {\n",
    "    \"maj_margin\": [80,100,120],\n",
    "    \"maj_thre\": [1,2,3],\n",
    "    \"zone_margin\":[80,100,120],\n",
    "    \"del_margin\": [80,100,120],\n",
    "    \"dtw_threshold\":[80,100,120]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# 21*98 = 2058 timeseries\n",
    "model_res=[]\n",
    "for model_id,model in enumerate(modelpred): #20 models predictions\n",
    "    param_value=[]\n",
    "    for p_idx,params in enumerate(ParameterGrid(param_grid)):\n",
    "        video=[]\n",
    "        for i in range(len(TIMESERIES)): #21 videos\n",
    "            df = dfl[i]\n",
    "            gt = gtl[i]\n",
    "            res=PostFilterTogether(model_id,i,p_idx,len(ParameterGrid(param_grid)),df.iloc[:,3],np.array(model[i],dtype=\"object\"),gt,params[\"maj_margin\"],params[\"maj_thre\"],params[\"zone_margin\"],params[\"del_margin\"],params[\"dtw_threshold\"])\n",
    "            video.append(res)\n",
    "            \"\"\"\n",
    "            i folds servono solo durante lo scoring\n",
    "            # single fold\n",
    "            train_set = [j for j in range(len(TIMESERIES)) if j != i]\n",
    "            test_set = i\n",
    "            for ts in train_set:\n",
    "                PostFilterTogether()\n",
    "            \"\"\"\n",
    "        param_value.append(video)\n",
    "    model_res.append(param_value)\n",
    "\n",
    "with open(\"../collection_models_prediction_filtered.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model_res, f)\n",
    "    \n",
    "    #fuori dal for deve calcolare la media\n",
    "    \n",
    "\"\"\"\n",
    "versione 1\n",
    "fisso param_grid\n",
    "calcolo f1 score per only training fold\n",
    "prendo il migliore\n",
    "calcolo per ogni singolo video nel validation\n",
    "\n",
    "for model in models:\n",
    "    for param in paramgrid:\n",
    "        for fold in folds:\n",
    "            for ts in fold.train:\n",
    "                f1s_1 = compute single f1score \n",
    "                calcolo f1score per singolo ts\n",
    "            f1s_mean = compute mean f1score mean(f1s_1,f1s_1,...)\n",
    "            per un intero train_set ritorno lo il f1score medio\n",
    "        f1s_mean_mean = compute mean of f1s_mean(f1s_mean,f1s_mean,...)\n",
    "        per ogni train_set ritorno la media = come performa questo param across all folds\n",
    "    check best f1s_mean_mean\n",
    "per ogni param diverso, controllo quello che mi massimizza\n",
    "O(n^3)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Scoring (8)</b>\n",
    "here we take as input all the filtered results and performs a cross-validation with our predictions to see which hyperparameters for our model+filter is the best and then test it on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../collection_models_prediction_filtered.pkl\", \"rb\") as f:\n",
    "    collection_models_prediction_filtered = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=collection_models_prediction_filtered\n",
    "# model:20 params:243 video:21 len_prediction:26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 16\u001b[0m\n\u001b[0;32m     12\u001b[0m score_singlefold_eachvideo\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ts \u001b[38;5;129;01min\u001b[39;00m train_set:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m#get score each video for ts\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m#compute score\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     _,_,f1,_,_,_\u001b[38;5;241m=\u001b[39m\u001b[43mf1scoremargin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvideos\u001b[49m\u001b[43m[\u001b[49m\u001b[43mts\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mf1_margin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     score_singlefold_eachvideo\u001b[38;5;241m.\u001b[39mappend(f1)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#media per training\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tikyn\\Desktop\\Uni\\TESI\\CUSUMMO\\core.py:308\u001b[0m, in \u001b[0;36mf1scoremargin\u001b[1;34m(ground_truth, predictions, tolerance)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf1scoremargin\u001b[39m(ground_truth, predictions, tolerance):\n\u001b[0;32m    301\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;124;03m    Calcola l'F1 score con una finestra di tolleranza sui change points.\u001b[39;00m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;124;03m    :param ground_truth: Lista o array di change points reali\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;124;03m    :param predictions: Lista o array di change points predetti\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;124;03m    :param tolerance: La tolleranza temporale (numero di unitÃ  temporali)\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;124;03m    :return: precision, recall, f1-score\u001b[39;00m\n\u001b[1;32m--> 308\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    309\u001b[0m     ground_truth \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(ground_truth)\n\u001b[0;32m    310\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(predictions)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# LEAVE ONE VIDEO OUT - LOVO\n",
    "f1_margin=100\n",
    "scores=[]\n",
    "for model_id,params in enumerate(models): #1 model = 243 params <- 20 model\n",
    "    for p_idx,videos in enumerate(params): # 21 video = 1 param <- 243 params\n",
    "        score_folds = []\n",
    "        for video_idx in range(len(TIMESERIES)): # 1 prediction = 1 video <- 1 param = 21 video\n",
    "\n",
    "            # single fold\n",
    "            train_set = [i for i in range(len(TIMESERIES)) if i != video_idx]\n",
    "            test_set = video_idx\n",
    "            score_singlefold_eachvideo=[]\n",
    "            for ts in train_set:\n",
    "                #get score each video for ts\n",
    "                #compute score\n",
    "                gt = gtl[ts]\n",
    "                _,_,f1,_,_,_=f1scoremargin(gt,videos[ts],f1_margin)\n",
    "                score_singlefold_eachvideo.append(f1)\n",
    "            #media per training\n",
    "            score_folds.append(statistics.mean(score_singlefold_eachvideo))\n",
    "        \n",
    "\n",
    "        scores.append({\"model\":model_id, \"param\":p_idx, \"score\":statistics.mean(score_folds)})\n",
    "\n",
    "type_col=[\"model\",\"param\",\"score\"]\n",
    "resexcel=pd.DataFrame()\n",
    "resexcel[\"type\"]=type_col\n",
    "best_models=[]\n",
    "best_score=0\n",
    "for i in scores:\n",
    "    if i[\"score\"] >= best_score:\n",
    "        best_models.append(i)\n",
    "best_scores=[]\n",
    "for best_idx,best in enumerate(best_models):\n",
    "    best_score=[]\n",
    "    for video_idx in range(len(TIMESERIES)):\n",
    "        gt = gtl[video_idx]\n",
    "        _,_,f1,_,_,_=f1scoremargin(gt,models[best[\"model\"]][best[\"param\"]][video_idx],f1_margin)\n",
    "        best_score.append(f1)\n",
    "    best_scores.append({\"model\":model_id, \"param\":p_idx, \"score\":statistics.mean(best_score)})\n",
    "    resexcel[best_idx]=[model_id,p_idx,statistics.mean(best_score)]\n",
    "\n",
    "resexcel.to_excel(\"outputFile/LOVO.xlsx\")\n",
    "print(\"lovo\")\n",
    "for i in best_scores:\n",
    "    print(i)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEAVE ONE DANCER OUT - LODO\n",
    "CORA=[0,1,2,3,4]\n",
    "MARIANNE=[5,6,7,8,9,10,11,12,13,14,15,16]\n",
    "MURIEL=[17,18,19,20]\n",
    "\n",
    "f1_margin=100\n",
    "scores=[]\n",
    "for model_id,params in enumerate(models): #1 model = 243 params <- 20 model\n",
    "    for p_idx,videos in enumerate(params): # 21 video = 1 param <- 243 params\n",
    "        score_folds = []\n",
    "        \n",
    "        #fold1\n",
    "        TRAINING_1 = CORA+MARIANNE\n",
    "        for ts in TRAINING_1:\n",
    "            #get score each video for ts\n",
    "            #compute score\n",
    "            gt = gtl[ts]\n",
    "            _,_,f1,_,_,_=f1scoremargin(gt,videos[ts],f1_margin)\n",
    "            score_singlefold_eachvideo.append(f1)\n",
    "        #media per training\n",
    "        fold1_score = statistics.mean(score_singlefold_eachvideo)\n",
    "\n",
    "        #fold2\n",
    "        TRAINING_2 = CORA+MURIEL\n",
    "        for ts in TRAINING_2:\n",
    "            #get score each video for ts\n",
    "            #compute score\n",
    "            gt = gtl[ts]\n",
    "            _,_,f1,_,_,_=f1scoremargin(gt,videos[ts],f1_margin)\n",
    "            score_singlefold_eachvideo.append(f1)\n",
    "        #media per training\n",
    "        fold2_score = statistics.mean(score_singlefold_eachvideo)\n",
    "\n",
    "        #fold3\n",
    "        TRAINING_3 = MARIANNE+MURIEL\n",
    "        for ts in TRAINING_3:\n",
    "            #get score each video for ts\n",
    "            #compute score\n",
    "            gt = gtl[ts]\n",
    "            _,_,f1,_,_,_=f1scoremargin(gt,videos[ts],f1_margin)\n",
    "            score_singlefold_eachvideo.append(f1)\n",
    "        #media per training\n",
    "        fold3_score = statistics.mean(score_singlefold_eachvideo)\n",
    "\n",
    "        training_mean_score = statistics.mean[fold1_score,fold2_score,fold3_score]\n",
    "        scores.append({\"model\":model_id, \"param\":p_idx, \"score\":training_mean_score})\n",
    "\n",
    "type_col=[\"model\",\"param\",\"score\"]\n",
    "resexcel=pd.DataFrame()\n",
    "resexcel[\"type\"]=type_col\n",
    "best_models=[]\n",
    "best_score=0\n",
    "for i in scores:\n",
    "    if i[\"score\"] >= best_score:\n",
    "        best_models.append(i)\n",
    "best_scores=[]\n",
    "for best_idx,best in enumerate(best_models):\n",
    "\n",
    "    #fold1\n",
    "    best_score=[]\n",
    "    for video_idx in CORA:\n",
    "        gt = gtl[video_idx]\n",
    "        _,_,f1,_,_,_=f1scoremargin(gt,models[best[\"model\"]][best[\"param\"]][video_idx],f1_margin)\n",
    "        best_score.append(f1)\n",
    "    fold1_score = statistics.mean(best_score)\n",
    "\n",
    "    #fold2\n",
    "    best_score=[]\n",
    "    for video_idx in MARIANNE:\n",
    "        gt = gtl[video_idx]\n",
    "        _,_,f1,_,_,_=f1scoremargin(gt,models[best[\"model\"]][best[\"param\"]][video_idx],f1_margin)\n",
    "        best_score.append(f1)\n",
    "    fold2_score = statistics.mean(best_score)\n",
    "\n",
    "    #fold3\n",
    "    best_score=[]\n",
    "    for video_idx in MURIEL:\n",
    "        gt = gtl[video_idx]\n",
    "        _,_,f1,_,_,_=f1scoremargin(gt,models[best[\"model\"]][best[\"param\"]][video_idx],f1_margin)\n",
    "        best_score.append(f1)\n",
    "    fold3_score = statistics.mean(best_score)\n",
    "\n",
    "    val_mean_score = statistics.mean([fold1_score,fold2_score,fold3_score])\n",
    "   \n",
    "    best_scores.append({\"model\":model_id, \"param\":p_idx, \"score\":val_mean_score})\n",
    "    resexcel[best_idx]=[model_id,p_idx,val_mean_score]\n",
    "\n",
    "resexcel.to_excel(\"outputFile/LODO.xlsx\")\n",
    "print(\"lodo\")\n",
    "for i in best_scores:\n",
    "    print(i)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
